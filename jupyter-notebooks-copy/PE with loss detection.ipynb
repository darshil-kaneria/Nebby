{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1aaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(\"../../website_measurements/singapore/top1k\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_wget = []\n",
    "for f in os.listdir(\"../../website_measurements/singapore/top1k\"):\n",
    "    if \"udp.csv\" in f :\n",
    "        continue\n",
    "    size = os.path.getsize(\"../../website_measurements/singapore/top1k/\" + f)\n",
    "    if size < 20000 :\n",
    "        no_wget.append(f)\n",
    "len(no_wget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nan_list:\n",
    "    for f in files:\n",
    "        if n in f and \"udp\" not in f:\n",
    "            try :\n",
    "                n_f = f[:-8]\n",
    "                data, time, retrans, rtt = plot_one_bt(n_f,\"n\",1)\n",
    "            except (KeyError,ValueError):\n",
    "                error.append(f)\n",
    "#                 print(f,\"is giving a measuring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, data, retrans, rtt = plot_one_bt(\"quora.com-0-50-200-2\",\"y\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad47afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be805418",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07884e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "for f in files:\n",
    "    name = f[:-8]\n",
    "    if name not in test_files:\n",
    "        test_files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced55fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3edbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in test_files:\n",
    "    time, data, retrans, rtt = plot_one_bt(f,\"n\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = checkBBR(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed199e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame([test_files,classi]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69820999",
   "metadata": {},
   "outputs": [],
   "source": [
    "why = [\"ebay.com-0-50-200-2\", \"salesforce.com-0-50-1000-2\", \"weather.com-0-50-1000-2\",\"rakuten.co.jp-0-50-1000-2\", \"amazon.it-0-50-1000-2\", \"csdn.net-0-50-200-2\", \"ebay.co.uk-0-50-1000-2\", \"vimeo.com-0-50-1000-2\", \"amazon.co.uk-0-50-200-2\", \"bet9ja.com-0-50-1000-2\", \"roblox.com-0-50-1000-2\", \"imdb.com-0-50-1000-2\", \"zillow.com-0-50-200-2\", \"indiatimes.com-0-50-1000-2\", \"amazon.co.jp-0-50-1000-2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_bbr = []\n",
    "for index,row in df.iterrows():\n",
    "    if row[1] == \"NO BBR\":\n",
    "        no_bbr.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(no_bbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in no_bbr:\n",
    "    time, data, retrans, rtt = plot_one_bt(f,\"y\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd33bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = []\n",
    "no = []\n",
    "nan = []\n",
    "for i in range(len(classi)):\n",
    "    if classi[i] == \"YES BBR\":\n",
    "        yes.append(test_files[i])\n",
    "    elif classi[i] == \"MAYBE BBR\":\n",
    "        no.append(test_files[i])\n",
    "    else:\n",
    "        nan.append(test_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yes), len(no), len(nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31457c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list = []\n",
    "for n in nan:\n",
    "    f = n.split(\"-\")[0]\n",
    "    print(f)\n",
    "    if f not in nan_list:\n",
    "        nan_list.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b753a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in yes:\n",
    "    time, data, retrans, rtt = plot_one_bt(f,\"n\",1)\n",
    "    probe_index = getProbes(time, data, rtt)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "    offset=0\n",
    "    ax.plot(time[offset:],data[offset:])\n",
    "    ax.set_title(f)\n",
    "    # for t in retrans :\n",
    "    #     if t > time[offset]:\n",
    "    #         plt.axvline(x = t, color = 'm',alpha=0.5)\n",
    "    # ax.plot(new_time[offset:], new_data[offset:])\n",
    "    for p in probe_index:\n",
    "        ax.plot(time[p[0]:p[1]+1], data[p[0]:p[1]+1], color='r', lw=2)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = \"alwafd.news,foxnews.com,yahoo.com,espn.com,51sole.com,trello.com,wikipedia.org,genius.com,doubleclick.net,alipay.com,bet9ja.com,roblox.com,hulu.com,medium.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = check_files.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = [f + \"-0-50-200-2\" for f in check_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c59922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eaa67ea",
   "metadata": {},
   "source": [
    "# Writing code for classifying the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6655624",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f365eca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f45070b8",
   "metadata": {},
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcdb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v = []\n",
    "for cc in v:\n",
    "    if cc not in [\"cdg\",\"hybla\",\"illinois\",\"bbr\"] :\n",
    "        new_v.append(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ce24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for cc in new_v :\n",
    "    for i in range(1,71):\n",
    "        if cc == 'bic':\n",
    "            if i in [2,9,26]:\n",
    "                continue\n",
    "        file = cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\"\n",
    "        train_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c67393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_unique_natural_numbers(start_range, end_range, count):\n",
    "    # If the range is smaller than the required count, adjust the count\n",
    "    count = min(count, end_range - start_range + 1)\n",
    "\n",
    "    # Create a list of numbers in the given range\n",
    "    numbers = list(range(start_range, end_range + 1))\n",
    "\n",
    "    # Generate unique random numbers using random.sample\n",
    "    unique_random_numbers = random.sample(numbers, count)\n",
    "\n",
    "    return unique_random_numbers\n",
    "\n",
    "# Define the range and the count of unique natural numbers\n",
    "start_range = 1\n",
    "end_range = 100\n",
    "count_of_unique_numbers = 10\n",
    "\n",
    "# Generate the unique natural numbers\n",
    "unique_natural_numbers = generate_unique_natural_numbers(start_range, end_range, count_of_unique_numbers)\n",
    "\n",
    "# Print the result\n",
    "print(unique_natural_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "# indices = generate_unique_natural_numbers(1,50,20)\n",
    "indices = [i for i in range(71,100)]\n",
    "for cc in new_v :\n",
    "    for i in indices:\n",
    "        file = cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\"\n",
    "        test_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ab3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf31d2b",
   "metadata": {},
   "source": [
    "# Checking the distribution of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_vals['cubic'][1]:\n",
    "    plt.hist(new_vals['cubic'][1][i],bins=10)\n",
    "    print(new_vals['cubic'][1][i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e21399",
   "metadata": {},
   "source": [
    "# Checking the determinant of the covariance for the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c962979",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cc in cc_gaussian_params:\n",
    "    print(cc, \"Covar\", np.linalg.det(cc_gaussian_params[cc]['covar']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac3904",
   "metadata": {},
   "source": [
    "# Checking the value of all the coefficients for a particular algo in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70227c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ['dctcp']\n",
    "f = \"\"\n",
    "for i in range(0,6):\n",
    "    f+=\"{:>10}\"\n",
    "    \n",
    "for cc in check:\n",
    "    c = 1\n",
    "    var = []\n",
    "    mean = []\n",
    "    for row in vals[cc][1]:\n",
    "        new_row = [round(i,5) for i in row]\n",
    "        print(str(c)+f.format(*new_row))\n",
    "        c+=1\n",
    "    print()\n",
    "    for i in range(0,6):\n",
    "        mean.append(round(cc_gaussian_params[cc]['mean'][i],5))\n",
    "    print(str(\"Me\")+f.format(*mean))\n",
    "    \n",
    "    for i in range(0,6):\n",
    "        var.append(round(cc_gaussian_params[cc]['covar'][i][i],5))\n",
    "    print(str(\"Va\")+f.format(*var))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a2417",
   "metadata": {},
   "source": [
    "# Check the mean and variance for each of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"\"\n",
    "for i in range(0,MAX_DEG+1):\n",
    "    f+=\"{:>10}\"\n",
    "    \n",
    "for cc in new_v:\n",
    "    c = 1\n",
    "    var = []\n",
    "    mean = []\n",
    "    print(cc)\n",
    "    for i in range(0,6):\n",
    "        mean.append(round(cc_gaussian_params[cc]['mean'][i],5))\n",
    "    print(str(\"Me\")+f.format(*mean))\n",
    "    \n",
    "    for i in range(0,6):\n",
    "        var.append(round(cc_gaussian_params[cc]['covar'][i][i],5))\n",
    "    print(str(\"Va\")+f.format(*var))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d94261",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEG=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b94aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71beef",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all once \n",
    "vals, new_vals, cc_gaussian_params = train(ccs,train_files)\n",
    "vals_test, new_vals_test = collect_test_data(ccs,test_files)\n",
    "acc_m, top, error = get_test_accuracy(vals_test, cc_gaussian_params)\n",
    "acc_data = getAccuracy(top,n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81b443",
   "metadata": {},
   "source": [
    "# Printing accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(acc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae64e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in acc_data:\n",
    "    print(i)\n",
    "    print(acc_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8f9a7",
   "metadata": {},
   "source": [
    "# Print top predictions for a cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1605407",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = 'yeah'\n",
    "res = top[cc]\n",
    "print(cc)\n",
    "count = 1\n",
    "for item in res :\n",
    "    print(count)\n",
    "    count+=1\n",
    "#     curr_row = np.array(res[item]['vals'])\n",
    "#     curr_row*=(10**10)\n",
    "    print(red + \"{: >30} {: >30} {: >30}\".format(*res[item]['cc']))\n",
    "#     print(\"{: >30} {: >30} {: >30}\".format(*curr_row))\n",
    "    print(blue+\"{: >30} {: >30} {: >30}\".format(*res[item]['new_vals']\n",
    "                                               ))\n",
    "#     print(\"%\", res[item]['cc'])\n",
    "#     print(\"Val\", res[item]['vals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d115e2",
   "metadata": {},
   "source": [
    "\n",
    "# Print the confusion matrix for current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe081a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(ccs, top):    \n",
    "    matrix = []\n",
    "    for cc in ccs:\n",
    "        # The underlying CC\n",
    "        temp = []\n",
    "        total = len(top[cc].keys())\n",
    "        cc_index = ccs.index(cc)\n",
    "        for check_cc in ccs :\n",
    "            # The CC it gets classified as\n",
    "            count = 0\n",
    "            for i in range(0,len(top[cc].keys())):\n",
    "                if i not in top[cc]:\n",
    "                    continue\n",
    "                if top[cc][i]['cc'][0]==check_cc:\n",
    "                    count+=1\n",
    "            temp.append(count)\n",
    "        temp.append(float(temp[cc_index])*100/total)\n",
    "        matrix.append(temp)\n",
    "    rows = [cc for cc in ccs]\n",
    "    columns = [cc for cc in ccs]\n",
    "    columns.append(\"accuracy\")\n",
    "    df = pd.DataFrame(matrix,index=rows,columns=columns)\n",
    "    print(\"Rows are the truth. Columns are the classifications\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245128e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = print_confusion_matrix(new_v, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac45984",
   "metadata": {},
   "source": [
    "# Code for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a702cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "def getPDensity(curr, cc_gaussian_params):\n",
    "    prob = {}\n",
    "    for cc in cc_gaussian_params:\n",
    "        mn = cc_gaussian_params[cc]['mean']\n",
    "        covar = cc_gaussian_params[cc]['covar']\n",
    "#         print(\"CC being checked against\",cc)\n",
    "#         print(np.linalg.det(covar))\n",
    "        curr_p = mvn.pdf(curr,mean=mn, cov=covar, allow_singular=True)\n",
    "        prob[cc]=curr_p\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(top):\n",
    "    for cc in top :\n",
    "        print()\n",
    "        print(cc)\n",
    "        print()\n",
    "        for i in top[cc]:\n",
    "            print(i)\n",
    "            for d in top[cc][i]:\n",
    "                print(top[cc][i][d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60293076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(vals_test, cc_gaussian_param):\n",
    "    acc_m = {}\n",
    "    for cc in vals_test:\n",
    "        if cc not in acc_m :\n",
    "            acc_m[cc] = []\n",
    "        if len(list(vals_test[cc].keys()))==0:\n",
    "            continue\n",
    "        data = vals_test[cc][1]\n",
    "        for curr in data:\n",
    "            p_dense = getPDensity(curr, cc_gaussian_params)\n",
    "            acc_m[cc].append(p_dense)\n",
    "    top = {}\n",
    "    error = {}\n",
    "    for cc in acc_m :\n",
    "        top[cc] = {}\n",
    "        ind = 0\n",
    "        for item in acc_m[cc]:\n",
    "            ccs = np.array(list(item.keys()))\n",
    "            vals = np.array(list(item.values()))\n",
    "            if min(vals) == 0:\n",
    "                if max(vals) < 1 : \n",
    "                    #This is an arbitrary constant\n",
    "                    if cc not in error :\n",
    "                        error[cc] = []\n",
    "                        error[cc].append(ind)\n",
    "                        ind+=1\n",
    "                        continue        \n",
    "            new_vals = (vals-min(vals))/(max(vals)-min(vals))\n",
    "            index_list =list(np.argsort(new_vals))\n",
    "            index_list.reverse()\n",
    "            cc_list = [ccs[i] for i in index_list]\n",
    "            vals_list = [vals[i] for i in index_list]\n",
    "            new_vals_list = [new_vals[i] for i in index_list]\n",
    "            top[cc][ind] = {}\n",
    "            top[cc][ind]['cc'] = cc_list[0:3]\n",
    "            top[cc][ind]['vals'] = vals_list[0:3]\n",
    "            top[cc][ind]['new_vals'] = new_vals_list[0:3]\n",
    "            ind+=1\n",
    "    return acc_m, top, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958835a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(acc_data):\n",
    "    for cc in acc_data:\n",
    "        new_dict = acc_data[cc]\n",
    "        print()\n",
    "        print(cc)\n",
    "        print(\"Accuracy :\", round(new_dict['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbfe5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(top,n=10):\n",
    "    acc_data = {}\n",
    "    for cc in top :\n",
    "        acc_data[cc] = {}\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for item in top[cc]:\n",
    "            curr = top[cc][item]\n",
    "            for i in range(min(3,len(curr['new_vals']))):\n",
    "                if curr['new_vals'][i] > 0.90 :\n",
    "                    if curr['cc'][i] not in acc_data[cc]:\n",
    "                        acc_data[cc][curr['cc'][i]] = 0\n",
    "                    acc_data[cc][curr['cc'][i]] += 1\n",
    "                    if curr['cc'][i] == cc :\n",
    "                        correct += 1\n",
    "                    else : \n",
    "                        incorrect += 1\n",
    "        incorrect += n - len(top[cc])\n",
    "        acc_data[cc]['correct'] = correct\n",
    "        acc_data[cc]['incorrect'] = incorrect\n",
    "        acc_data[cc]['accuracy'] = (correct*100)/(correct+incorrect)\n",
    "    return acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee122914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_test_data(var, present_files):\n",
    "    cc_coeff_test = getCCcoeff(var,present_files,ss=225,p=\"n\",ft_thresh=1)\n",
    "    vals_test, new_vals_test = getCoeff(cc_coeff_test)\n",
    "    return vals_test, new_vals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0749cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(var, present_files,ss=225):\n",
    "    cc_coeff = getCCcoeff(var,present_files,ss=ss,ft_thresh=1)\n",
    "    vals, new_vals = getCoeff(cc_coeff, \"\", p=\"n\")\n",
    "    cc_gaussian_params = getGaussianParams(vals)\n",
    "    return vals, new_vals, cc_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaussianParams(vals):\n",
    "    cc_gaussian_params = {}\n",
    "    for cc in vals :\n",
    "        # Taking the first feature only\n",
    "        if len(list(vals[cc].keys()))==0 :\n",
    "            continue\n",
    "        data = vals[cc][1]\n",
    "        n = 0\n",
    "        cc_coeff_mean = np.mean(data,axis=0)\n",
    "        coeff_var = np.cov(data, rowvar=False)\n",
    "        iden = np.identity(len(cc_coeff_mean))\n",
    "        cc_coeff_var = coeff_var * iden\n",
    "        cc_gaussian_params[cc] = {\n",
    "            'mean' : cc_coeff_mean,\n",
    "            'covar' : cc_coeff_var\n",
    "        }\n",
    "    return cc_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49230e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoeff(cc_coeff):\n",
    "    vals = {}\n",
    "    degree = 0\n",
    "    for cc in cc_coeff:\n",
    "        coeff = cc_coeff[cc]\n",
    "        if cc not in vals :\n",
    "            vals[cc] = {}\n",
    "        for trace in coeff:\n",
    "            i = 1\n",
    "            for feature in trace:\n",
    "                if i not in vals[cc]:\n",
    "                    vals[cc][i] = []\n",
    "                degree = len(feature)-1\n",
    "                vals[cc][i].append(feature)\n",
    "                i+=1\n",
    "    new_vals = {}\n",
    "    coe = []\n",
    "    coeff_count = degree+1\n",
    "    for i in range(0,coeff_count):\n",
    "        coe.append(\"c\"+str(i))\n",
    "    for cc in vals:\n",
    "        new_vals[cc] = {}\n",
    "        for i in vals[cc]:\n",
    "            new_vals[cc][i] = {}\n",
    "            c_val = {}\n",
    "            for x in range(0,coeff_count):\n",
    "                c_val[\"c\"+str(x)] = []\n",
    "            for ft in vals[cc][i]:\n",
    "                for x in range(0,coeff_count):\n",
    "                    c_val[coe[x]].append(ft[x])\n",
    "            for x in range(0,coeff_count):\n",
    "                new_vals[cc][i][coe[x]] = c_val[coe[x]]\n",
    "    return vals, new_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf369a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCCcoeff(ccs,present_files,ss=225,p=\"n\",ft_thresh=100):\n",
    "    cc_coeff = {}\n",
    "    for v in ccs: \n",
    "        files = []\n",
    "        for f in present_files:\n",
    "            curr_cc = f.split(\"-\")[0]\n",
    "            if v == curr_cc :\n",
    "                files.append(f)        \n",
    "        if len(files) > 0 :\n",
    "            cc_mp = get_feature_degree(files,ss=ss,p=p,ft_thresh=ft_thresh)\n",
    "            coeff = getCC(files, cc_mp,p=p)\n",
    "            print(v)\n",
    "            print(files)\n",
    "            cc_coeff[v] = coeff[v]\n",
    "        #     getRed(files,p=\"y\")\n",
    "    return cc_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f84de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = []\n",
    "# curr_v = ['bic']\n",
    "# curr_v = ['vegas','veno','dctcp']\n",
    "curr_v = ['nv']\n",
    "# for cc in new_v :\n",
    "# r = [31,33,34,35,36,42,47]\n",
    "for i in range(1,10):\n",
    "    for cc in curr_v:\n",
    "    # for i in r:\n",
    "        file = cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\"\n",
    "        check_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_coeff = getCCcoeff(new_v, files, ss=225,p=\"n\",ft_thresh=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14eec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, new_vals = getCoeff(cc_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_gaussian_params = getGaussianParams(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f061c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mp, errors = get_feature_degree(check_files, ss=225, p=\"y\",ft_thresh=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d64b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_mp, errors = get_feature_degree(check_files, ss=225, p=\"y\",ft_thresh=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_coeff = getCC(check_files, cc_mp, p='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cad995",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mp = get_feature_degree(files,ss=225,p=\"n\",ft_thresh=1,max_deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa155c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_coeff = getCC(files,cc_mp,p=\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb021dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "def get_degree(time,data, p=\"n\", max_deg=MAX_DEG):\n",
    "    p_net = []\n",
    "    mse_l = []\n",
    "    fit_net = []\n",
    "    for d in range(1,max_deg+1):\n",
    "        p_temp = np.polyfit(time,data, d)\n",
    "        p_net.append(p_temp)\n",
    "        fit_net.append(np.polyval(p_temp,time))\n",
    "        mse_l.append(mse(data,fit_net[-1]))\n",
    "    if p =='y':\n",
    "#         print(\"1 \", p1, \"MSE \", mse(data, fit_l))\n",
    "        plt.plot(time, data,c='k',label='Truth')\n",
    "#         plt.plot(time, fit_l)\n",
    "        for d in range(max_deg-1, max_deg):\n",
    "            plot_label = \"degree\"+str(d)\n",
    "            plt.plot(time, fit_net[d],label=\"degree\" + str(d+1))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return max_deg,p_net[max_deg-1], mse_l\n",
    "\n",
    "def normalize(time, data, rtt, bdp):\n",
    "    new_time = (time/rtt)\n",
    "    new_data = (data/bdp)*100\n",
    "    new_time -=min(new_time)\n",
    "    new_data -=min(new_data)\n",
    "    return new_time, new_data\n",
    "    \n",
    "from statistics import mean \n",
    "def get_feature_degree(files,ss=225,p='n',ft_thresh=3,max_deg=MAX_DEG):\n",
    "    results = getRed(files,ss,p=p,ft_thresh=ft_thresh)\n",
    "    errors = []\n",
    "    mp = {}\n",
    "    cc_mp = {}\n",
    "    count_features = 0\n",
    "    for item in results :\n",
    "        for ele in list(item.keys()):\n",
    "            name_list = ele.split(\"_\")\n",
    "            cc = name_list[0]\n",
    "            name = name_list[0] + name_list[-1]\n",
    "            if \"data\" in ele :\n",
    "                curr_data = np.array(item[ele])\n",
    "            if \"time\" in ele :\n",
    "                curr_time = np.array(item[ele])\n",
    "            if \"rtt\" in ele :\n",
    "                curr_rtt = item[ele]\n",
    "            if \"bdp\" in ele :\n",
    "                curr_bdp = item[ele]\n",
    "        curr_time, curr_data = normalize(curr_time, curr_data, curr_rtt, curr_bdp)\n",
    "        count_features += 1\n",
    "        print(\"Name :\",name)\n",
    "        degree, coeff, error_item = get_degree(curr_time, curr_data,p=p,max_deg=max_deg)\n",
    "        mp[name] = {'d':degree, 'coeff':coeff, 'error':error_item, 'data':curr_data, 'time':curr_time}\n",
    "        if cc not in cc_mp :\n",
    "            cc_mp[cc] = []\n",
    "        cc_mp[cc].append(mp[name])\n",
    "    return cc_mp\n",
    "\n",
    "def getCC(files,cc_mp, p=\"n\"):\n",
    "    # experiment change start\n",
    "    cc_coeff = {}\n",
    "    for file in files :\n",
    "#         file = v + \"-0-50-1000-2\"\n",
    "        curr_file = file\n",
    "        f_split = file.split(\"-\") \n",
    "        cc = f_split[0]\n",
    "        version = f_split[1]\n",
    "        v = cc+\"-\"+version\n",
    "        if cc not in cc_coeff:\n",
    "            cc_coeff[cc] = []\n",
    "    # experiment change end\n",
    "        time, data, retrans, rtt = plot_one_bt(curr_file, p)\n",
    "        count = 0\n",
    "        temp = []\n",
    "        if v not in cc_mp.keys():\n",
    "            continue\n",
    "        n = math.ceil(float(len(cc_mp[v]))/3)\n",
    "        for item in cc_mp[v]:\n",
    "            time = item['time']\n",
    "            data = item['data']\n",
    "            deg = item['d']\n",
    "            temp.append(item['coeff'])    \n",
    "            xlim = 0\n",
    "            ylim = 0\n",
    "            t = 1\n",
    "            while time[-1] > t:\n",
    "                t*=2\n",
    "            xlim = t\n",
    "            while data[-1] > t:\n",
    "                t*=2\n",
    "            ylim = t\n",
    "            lim = max(xlim, ylim)\n",
    "            print(lim)\n",
    "            names = []\n",
    "            bars=[]\n",
    "            for i in range(1,deg+1):\n",
    "                bars.append(i)\n",
    "                names.append(str(i))\n",
    "            print(names)\n",
    "            print(item['error'])\n",
    "            count+=1\n",
    "            if p == 'y':\n",
    "                print([round(x,5) for x in item['coeff']])\n",
    "                plt.plot(time,data)\n",
    "                plt.plot(time, np.polyval(item['coeff'],time))\n",
    "                plt.xlim(0,lim)\n",
    "                plt.ylim(0,lim)\n",
    "                plt.title(str(count)+\" \" + cc)\n",
    "                plt.show()\n",
    "#                 Showing the coefficient magnitude on a bar plot\n",
    "#                 plt.figure().set_figwidth(4)\n",
    "#                 plt.figure().set_figheight(2)\n",
    "#                 plt.bar([i for i in range(1,deg+2)], item['coeff'])\n",
    "#                 plt.show()\n",
    "#                 Showing the change in error magnitute on a bar plot\n",
    "                plt.figure().set_figwidth(4)\n",
    "                plt.figure().set_figheight(2)\n",
    "                plt.bar(bars, item['error'][0:deg], tick_label=names)\n",
    "                plt.show()\n",
    "        cc_coeff[cc].append(temp)\n",
    "    return cc_coeff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc09da",
   "metadata": {},
   "source": [
    "# Break 2\n",
    "# This code trims the features and reduces dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = []\n",
    "# neww_v = [\"dctcp\", \"lp\", \"scalable\", \"reno\"]\n",
    "for cc in new_v :\n",
    "    for i in range(1,2):\n",
    "        file = cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\"\n",
    "        check_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7081b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_mp, errors = get_feature_degree(check_files,ss=225,ft_thresh=1)\n",
    "cc_coeff  = getCC(check_files, cc_mp, p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e33d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=\"reno cubic bbr\"\n",
    "v = variants.split(\" \")\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=\"bic cdg dctcp highspeed htcp hybla illinois lp nv scalable vegas veno westwood yeah cubic bbr reno\"\n",
    "v = variants.split(\" \")\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9a631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cc = \"bic\"\n",
    "check_files = []\n",
    "postdelays = [100]\n",
    "linkspeeds =[150]\n",
    "buffsizes = [1]\n",
    "for cc in v:\n",
    "    for postdelay in postdelays:\n",
    "        for linkspeed in linkspeeds:\n",
    "            for buffsize in buffsizes:\n",
    "                for i in range(1,2):\n",
    "                    name = [cc,str(i),\"0\",str(postdelay),str(linkspeed),str(buffsize),\"aws-88-45\"]\n",
    "                    file_name = \"-\".join(name)\n",
    "                    try :\n",
    "                        time, data , retrans = plot_one_bt([file_name], p=\"y\")\n",
    "                        check_files.append(file_name)\n",
    "                    except Exception as e :\n",
    "                        print(e)\n",
    "                        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d278da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "def lower_bound(arr, target):\n",
    "    index = bisect.bisect_left(arr, target)\n",
    "    return index\n",
    "\n",
    "def sample_data_time(time, data, ss, m):\n",
    "    curr_time, curr_data = adjust(time, data)\n",
    "    tp = curr_time[len(curr_time)-1] - curr_time[0]\n",
    "    step = tp/m\n",
    "    samp_time = [curr_time[0] + i*step for i in range(m)]\n",
    "    x = np.random.uniform(0,math.pi,ss)\n",
    "    tr_x = np.cos(x)\n",
    "    tr_x += 1\n",
    "    tr_x *= (m-1)/2\n",
    "    ind = [int(round(e, 0)) for e in tr_x]\n",
    "    sort_ind = sorted(ind)\n",
    "    tr_time = [samp_time[i] for i in sort_ind]\n",
    "    new_time = []\n",
    "    new_data = []\n",
    "    for t in tr_time :\n",
    "        i = lower_bound(curr_time, t)\n",
    "        temp_t = 0\n",
    "        temp_d = 0\n",
    "        if round(t,6) == round(curr_time[i],6):\n",
    "            temp_t = curr_time[i]\n",
    "            temp_d = curr_data[i]\n",
    "        else : \n",
    "            if i == 0 :\n",
    "                temp_t = curr_time[i]\n",
    "                temp_d = curr_data[i]\n",
    "            elif i == len(curr_time)-1 :\n",
    "                temp_t = curr_time[i]\n",
    "                temp_d = curr_data[i]\n",
    "            else :\n",
    "                temp_t = (curr_time[i-1] + curr_time[i])/2\n",
    "                temp_d = (curr_data[i-1] + curr_data[i])/2\n",
    "        new_time.append(temp_t)\n",
    "        new_data.append(temp_d)\n",
    "#     return curr_time, curr_data\n",
    "    return new_time, new_data\n",
    "\n",
    "def adjust(time, data):\n",
    "    start = data.index(min(data[:int(len(data)/2)]))\n",
    "    end = data.index(max(data[int(len(data)/2):]))\n",
    "#     print(\"Difference in max and min \", end-start)\n",
    "    if end - start <= 0: \n",
    "        return time, data\n",
    "    new_time = time[start:end+1]\n",
    "    new_data = data[start:end+1]\n",
    "    return new_time, new_data\n",
    "\n",
    "# Taking 100 as the threshold is fine \n",
    "# Now we have to see how the graphs look if we use it. \n",
    "# var = [\"reno\", \"cubic\", \"bbr\"]\n",
    "def getRed(files,ss=125,p=\"y\", ft_thresh=100):\n",
    "    results = []\n",
    "    for file in files :   \n",
    "        f_split = file.split(\"-\")\n",
    "        v = f_split[0] + \"-\" + f_split[1]\n",
    "        rtt = float((int(f_split[2]) + int(f_split[3]))*2)/1000\n",
    "        bdp = float(rtt*1000*int(f_split[4])*int(f_split[5]))/8\n",
    "        print(file)\n",
    "        print(\"RTT\",rtt,\"BDP\",bdp)\n",
    "        time, data, features = get_plot_features(file, p=p)\n",
    "        count = 1\n",
    "        for ft in features : \n",
    "            if count > ft_thresh:\n",
    "                break\n",
    "            curr_time = time[ft[0]:ft[1]+1]\n",
    "            curr_data = data[ft[0]:ft[1]+1]\n",
    "            tr_time, tr_data = sample_data_time(curr_time, curr_data, ss, 1000)\n",
    "            tr_time_pd = pd.DataFrame(tr_time)\n",
    "            tr_data_pd = pd.DataFrame(tr_data)\n",
    "            tr_time = list(tr_time_pd.rolling(25, center=True).mean().dropna()[0])\n",
    "            tr_data = list(tr_data_pd.rolling(25, center=True).mean().dropna()[0])\n",
    "            print(\"Feature Length \", len(tr_data))\n",
    "            if p == \"y\" :\n",
    "                plt.plot(curr_time, curr_data, c='b', alpha = 0.5, lw = 5)\n",
    "                plt.plot(tr_time, tr_data, c='r', alpha = 1)\n",
    "                plt.scatter(tr_time, tr_data, c='k')\n",
    "#                 plt.scatter(tr_time, tr_data, c='r', s=10)\n",
    "                plt.title(v)\n",
    "                plt.show()\n",
    "            results.append(\n",
    "                {v+\"_\"+\"data\"+\"_\"+str(count):tr_data,\n",
    "                     v+\"_\"+\"time\"+\"_\"+str(count):tr_time,\n",
    "                        v+\"_\"+\"rtt\"+\"_\"+str(count):rtt, \n",
    "                             v+\"_\"+\"bdp\"+\"_\"+str(count):bdp})\n",
    "            count+=1\n",
    "    return results\n",
    "# results = getRed(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e572f",
   "metadata": {},
   "source": [
    "# Break 1 \n",
    "# Below code works to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86790b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "# for cc in v :\n",
    "cc='cubic'\n",
    "for i in range(8,10):\n",
    "    files.append(cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45c45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f89609",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = getRed(files,ss=225,p=\"n\",ft_thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bb942",
   "metadata": {},
   "source": [
    "# Writing the top classifies for BBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "v = ['bbr','cubic','reno']\n",
    "\n",
    "for cc in v :\n",
    "    for i in range(1,50):\n",
    "        files.append(cc+\"-\"+str(i)+\"-0-50-200-2-aws-88-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi = checkBBR(check_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a65485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([files,classi]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532683b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d52f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = []\n",
    "non_check_files = []\n",
    "for i in range(len(classi)):\n",
    "    if classi[i] == 'NO BBR':\n",
    "        check_files.append(files[i])\n",
    "    if classi[i] == 'YES BBR':\n",
    "        non_check_files.append(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_check_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb45f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in check_files:\n",
    "    time, data, retrans,rtt = plot_one_bt(f,p=\"y\",t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for t in time_dis : \n",
    "    temp_t = t/rtt\n",
    "    key = math.floor(temp_t/10)\n",
    "    if key not in count:\n",
    "        count[key]=0\n",
    "        div[key]=[]\n",
    "    count[key]+=1 \n",
    "    div[key].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_time_dis = sorted(time_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bbd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_10_20 = div[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c037f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_10_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(bet_10_20)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c166633",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bet_10_20, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31471c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getendMA(time,data, rtt):\n",
    "    left = 0\n",
    "    right = 0\n",
    "    run_sum = data[left]\n",
    "    new_data = []\n",
    "    new_time = []\n",
    "#     we will try out averaging the time and not averaging the time both the ways\n",
    "# we will also try out with *RTT because that is the final thing\n",
    "    while(right < len(data)):\n",
    "        while(right < len(data) and time[right]-time[left] < 8*rtt):\n",
    "            run_sum+=data[right]\n",
    "            right+=1\n",
    "        new_data.append(run_sum/(right-left))\n",
    "        new_time.append(time[right-1])\n",
    "        run_sum -= data[left]\n",
    "        left+=1\n",
    "    return new_time, new_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseEndMA(time,data,rtt):\n",
    "    right = len(data)-1\n",
    "    left = len(data)-1\n",
    "    run_sum=data[right]\n",
    "    new_data = []\n",
    "    new_time= []\n",
    "    while(left >= 0):\n",
    "        while(left >= 0 and time[right]-time[left] < 8*rtt):\n",
    "            run_sum+=data[left]\n",
    "            left-=1\n",
    "        new_data.append(run_sum/(right-left))\n",
    "        new_time.append(time[right])\n",
    "        run_sum -= data[right]\n",
    "        right-=1\n",
    "    new_data.reverse()\n",
    "    new_time.reverse()\n",
    "    return new_time, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdp_2 = 5000\n",
    "bdp_10 = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaecf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbes_o(time, data, rtt, bdp):\n",
    "    thresh = 8*rtt\n",
    "    st_thresh = 0.025\n",
    "    error = 0.02\n",
    "    alpha = 1.10\n",
    "    probe_index = []\n",
    "    left = 0\n",
    "    right = 0\n",
    "    bdp_thresh = bdp/2\n",
    "    prev_right = 0\n",
    "    end = 0\n",
    "    while right < len(data):\n",
    "        while right < len(data) and (time[right]-time[left]) < thresh:\n",
    "            right+=1\n",
    "        mid = math.floor(left + (right - left)/2)\n",
    "        if right == len(data):\n",
    "            end = 1\n",
    "            right-=1\n",
    "        go = 0\n",
    "        if data[mid] > data[left] and data[mid] > data[right]:\n",
    "            #this  is  peak\n",
    "#             go = 1\n",
    "            t_l = left\n",
    "            t_r = right\n",
    "            while(t_l > 0 and time[left]-time[t_l] < thresh/2):\n",
    "                t_l-=1\n",
    "            while(t_r < len(data)-1 and time[t_r]-time[right] < thresh/2):\n",
    "                t_r+=1\n",
    "            left_sd = round(np.std(data[t_l:left])/(bdp_thresh*2),3)\n",
    "            right_sd = round(np.std(data[right:t_r])/(bdp_thresh*2),3)\n",
    "            if float(abs(data[left]-data[right]))/data[left] < error:\n",
    "                # this has the left and right points not too different from each other\n",
    "                side_avg = float((data[left]+data[right]))/2\n",
    "                local_max = max(data[left:right+1])\n",
    "#                 go = 1\n",
    "#                 print(\"Yes\")\n",
    "                if float(local_max)/side_avg > alpha and local_max > bdp_thresh: \n",
    "                    # this means that the peak is quite steep\n",
    "#                     print(\"This\")\n",
    "                    go = 1\n",
    "                    if (left_sd < st_thresh) and (right_sd < st_thresh):\n",
    "                        # this means that the lest and right are quite stable respectvely\n",
    "#                         go = 1\n",
    "                        print(\"Out\", left_sd, right_sd, st_thresh)\n",
    "        if go == 1: \n",
    "            try :\n",
    "                probe_index.append([left,right,float(local_max)/side_avg, time[right]-time[left], left_sd, right_sd, t_l,t_r])\n",
    "            except :\n",
    "                probe_index.append([left,right])\n",
    "            #Once you have found something you directly move past it\n",
    "            left = right-1\n",
    "        if end:\n",
    "            right+=1\n",
    "        left+=1\n",
    "    return probe_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbes(time, data, rtt, bdp, bw=200):\n",
    "    if bw==200:\n",
    "        thresh = 8*rtt\n",
    "        st_thresh = 0.025\n",
    "        error = 0.08\n",
    "        alpha = 1.10\n",
    "    if bw==1000:\n",
    "        thresh = 4*rtt\n",
    "        st_thresh = 0.025\n",
    "        error = 0.02\n",
    "        alpha = 1\n",
    "    probe_index = []\n",
    "    left = 0\n",
    "    right = 0\n",
    "    bdp_thresh = bdp/2\n",
    "    prev_right = 0\n",
    "    end = 0\n",
    "    while right < len(data):\n",
    "        while right < len(data) and (time[right]-time[left]) < thresh:\n",
    "            right+=1\n",
    "        if right == len(data):\n",
    "            end = 1\n",
    "            right-=1\n",
    "        mid = math.floor(left + (right - left)/2)\n",
    "        mid_val = 0\n",
    "        left_mid = mid\n",
    "        right_mid = mid\n",
    "#         print(left,right)\n",
    "#         while left_mid > 0 and abs(time[mid]-time[left_mid])<rtt:\n",
    "#             if data[left_mid] > data[left] and data[left_mid] > data[right]:\n",
    "#                 mid_val+=1\n",
    "#             left_mid-=1\n",
    "#         while right_mid < len(data)-1 and abs(time[right_mid]-time[mid])<rtt:\n",
    "#             if data[right_mid] > data[left] and data[right_mid] > data[right]:\n",
    "#                 mid_val+=1\n",
    "#             right_mid+=1\n",
    "#         total = right_mid - left_mid\n",
    "#         peak = 0\n",
    "#         if round(float(mid_val)/total,2) > 0.99 :\n",
    "#             print(round(float(mid_val)/total,2))\n",
    "#             peak=1\n",
    "        go = 0\n",
    "        if data[mid] > data[left] and data[mid] > data[right]:\n",
    "#         if peak == 1:\n",
    "            #this  is  peak\n",
    "#             go = 1\n",
    "            t_l = left\n",
    "            t_r = right\n",
    "            while(t_l > 0 and time[left]-time[t_l] < thresh/2):\n",
    "                t_l-=1\n",
    "            while(t_r < len(data)-1 and time[t_r]-time[right] < thresh/2):\n",
    "                t_r+=1\n",
    "            left_sd = round(np.std(data[t_l:left])/(bdp_thresh*2),3)\n",
    "            right_sd = round(np.std(data[right:t_r])/(bdp_thresh*2),3)\n",
    "            if float(abs(data[left]-data[right]))/data[left] < error:\n",
    "                # this has the left and right points not too different from each other\n",
    "                side_avg = float((data[left]+data[right]))/2\n",
    "                local_max = max(data[left:right+1])\n",
    "#                 go = 1\n",
    "#                 print(\"Yes\")\n",
    "                if float(local_max)/side_avg > alpha and local_max > bdp_thresh: \n",
    "                    # this means that the peak is quite steep\n",
    "#                     print(\"This\")\n",
    "#                     go = 1\n",
    "                    if (left_sd < st_thresh) and (right_sd < st_thresh):\n",
    "                        # this means that the lest and right are quite stable respectvely\n",
    "                        go = 1\n",
    "#                         print(\"Out\", left_sd, right_sd, st_thresh)\n",
    "        if go == 1: \n",
    "            try :\n",
    "                probe_index.append([left,right,float(local_max)/side_avg, time[right]-time[left], left_sd, right_sd, t_l,t_r])\n",
    "            except :\n",
    "                probe_index.append([left,right])\n",
    "            #Once you have found something you directly move past it\n",
    "            left = right-1\n",
    "        if end:\n",
    "            right+=1\n",
    "        left+=1\n",
    "    return probe_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_index=14\n",
    "para = why[check_index].split(\"-\")\n",
    "rtt = int(para[2])*2\n",
    "bw = int(para[3])\n",
    "bf = int(para[4])\n",
    "bdp = (rtt*bw*bf)/8\n",
    "time, data, retrans, rtt = plot_one_bt(why[check_index],\"y\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_index = getProbes(time, data, rtt,bdp,bw)\n",
    "for r in probe_index:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efade8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_red(time, data, probe_index)\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "offset=0\n",
    "ax.plot(time[offset:],data[offset:])\n",
    "# new_time, new_data = getendMA(time, data, rtt)\n",
    "# ax.plot(new_time, new_data, label=\"normal\", lw=5)\n",
    "# new_time, new_data = reverseEndMA(time, data, rtt)\n",
    "# ax.plot(new_time, new_data, label=\"reverse\")\n",
    "# for t in retrans :\n",
    "#     if t > time[offset]:\n",
    "#         plt.axvline(x = t, color = 'm',alpha=0.5)\n",
    "# ax.plot(new_time[offset:], new_data[offset:])\n",
    "for p in probe_index:\n",
    "    ax.plot(time[p[0]:p[1]+1], data[p[0]:p[1]+1], color='r', lw=2)\n",
    "#     ax.plot(time[p[-2]:p[0]], data[p[-2]:p[0]], color='k', lw=2)\n",
    "#     ax.plot(time[p[1]:p[-1]], data[p[1]:p[-1]], color='k', lw=2)\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi1=checkBBR([why[check_index]])\n",
    "classi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f67324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBBR(files):\n",
    "    classi = []\n",
    "    for f in files:\n",
    "        para = f.split(\"-\")\n",
    "        rtt = int(para[2])*2\n",
    "        bw = int(para[3])\n",
    "        bf = int(para[4])\n",
    "        bdp = float(bw*rtt*bf)/8\n",
    "        if bw == 1000 :\n",
    "            l=5\n",
    "            r=15\n",
    "        if bw == 200:\n",
    "            l=10\n",
    "            r=20\n",
    "        try:\n",
    "            time, data, retrans,rtt = plot_one_bt(f,p=\"n\",t=1)\n",
    "            probe_index = getProbes(time, data, rtt, bdp, bw)\n",
    "            prev = 0\n",
    "            time_dis = []\n",
    "            for p in probe_index:\n",
    "                curr_ind = data.index(max(data[p[0]:p[1]+1]))\n",
    "                if curr_ind > p[1] or curr_ind < p[0]:\n",
    "                    print(\"Something Wrong\")\n",
    "                if prev != 0:\n",
    "                    time_dis.append(abs(time[curr_ind]-prev))\n",
    "                prev = time[curr_ind]\n",
    "#             print(time_dis)\n",
    "            count = 0\n",
    "            isBBR = 0\n",
    "            for t in time_dis : \n",
    "                if  t > l*rtt and t < r*rtt :\n",
    "                    count+=1\n",
    "                    if count >= 2: # there are three peaks consecutively\n",
    "                        isBBR=1\n",
    "                        break\n",
    "                else:\n",
    "                    count = 0\n",
    "            if isBBR:\n",
    "                classi.append(\"YES BBR\")\n",
    "            else:\n",
    "                if len(probe_index) <= 1 :\n",
    "                    classi.append(\"NO BBR\")\n",
    "                else:\n",
    "                    classi.append(\"MAYBE BBR\")\n",
    "        except Exception as ex:  \n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            new_message = \"NC \" + message\n",
    "            classi.append(new_message)\n",
    "    return classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c440a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dis = []\n",
    "prev = 0\n",
    "for p in range(len(probe_index)-1):\n",
    "    time_dis.append(abs(time[probe_index[p+1][1]]-time[probe_index[p][0]]))\n",
    "print(len(probe_index))\n",
    "print(len(time_dis))\n",
    "print(time_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce81153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think it is better to use the maximum rather than end points because the end points are dependent on my parameters, the maximum is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dis = []\n",
    "prev = 0\n",
    "for p in probe_index:\n",
    "    curr_ind = data.index(max(data[p[0]:p[1]+1]))\n",
    "    if curr_ind > p[1] or curr_ind < p[0]:\n",
    "        print(\"Something Wrong\")\n",
    "    if prev != 0:\n",
    "        time_dis.append(abs(time[curr_ind]-prev))\n",
    "    prev = time[curr_ind]\n",
    "print(len(probe_index))\n",
    "print(len(time_dis))\n",
    "print(time_dis)\n",
    "count = 0\n",
    "for t in time_dis : \n",
    "    if t > 10*rtt and  t < 20*rtt:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_red(time,data,probe_index):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "    offset=0\n",
    "    ax.plot(time[offset:],data[offset:])\n",
    "    # for t in retrans :\n",
    "    #     if t > time[offset]:\n",
    "    #         plt.axvline(x = t, color = 'm',alpha=0.5)\n",
    "    # ax.plot(new_time[offset:], new_data[offset:])\n",
    "    for p in probe_index:\n",
    "        ax.plot(time[p[0]:p[1]+1], data[p[0]:p[1]+1], color='r', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4968e",
   "metadata": {},
   "source": [
    "OLD BTL 100-150-1-45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac68968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in files :\n",
    "    data, time, retrans = get_plot_features(f,p=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c271e38",
   "metadata": {},
   "source": [
    "NEW BTL 50-200-2-45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f0e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in files :\n",
    "    time, data, retrans,rtt = plot_one_bt(f,p=\"y\",t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"bbr-1-0-50-200-2-aws-88-60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff72dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, time, retrans = get_window(\"bbr-1-0-50-200-2-aws-88-60\",p=\"y\",t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fb977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, time, retrans = get_window(\"youtube.com-0-50-1000-2\",p=\"y\",t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c502333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = '\\033[93m'\n",
    "green = '\\033[92m'\n",
    "red = '\\033[91m'\n",
    "blue = '\\033[94m'\n",
    "pink = '\\033[95m'\n",
    "black = '\\033[90m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e36a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.fft import irfft\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, pstdev\n",
    "import pandas as pd\n",
    "\n",
    "def smoothen(time, data, rtt):\n",
    "    # Smoothening \n",
    "    left = 0\n",
    "    right = 0\n",
    "    run_sum = 0\n",
    "    avg_data = []\n",
    "    new_time = []\n",
    "    roll_time = time\n",
    "    roll_data = data\n",
    "    while right < len(roll_time):\n",
    "        while(right < len(roll_time) and (roll_time[right]-roll_time[left] < 2*rtt)):\n",
    "            run_sum+=roll_data[right]\n",
    "            right+=1\n",
    "        new_time.append(float(roll_time[right-1]+roll_time[left])/2)\n",
    "        avg_data.append(float(run_sum)/(right-left))\n",
    "        run_sum-=roll_data[left]\n",
    "        left+=1\n",
    "    return new_time, avg_data\n",
    "\n",
    "\n",
    "def get_fft(data):\n",
    "    n = len(data)\n",
    "    data_step = 0.002\n",
    "    yf = rfft(data)\n",
    "    xf = rfftfreq(n,data_step)\n",
    "    return yf,xf\n",
    "\n",
    "def get_fft_smoothening(data, time, ax,rtt,p):\n",
    "    rtt=rtt\n",
    "    yf, xf = get_fft(data)\n",
    "    thresh  = (1/rtt)\n",
    "    thresh_ind = 0\n",
    "    for i in range(len(xf)) :\n",
    "        freq = xf[i]\n",
    "        if(freq > thresh):\n",
    "            thresh_ind = i\n",
    "            break\n",
    "            \n",
    "    yf_clean = yf\n",
    "    yf_clean[thresh_ind+1:] = 0\n",
    "    new_f_clean = irfft(yf_clean)\n",
    "    start_len = len(time) - len(new_f_clean)\n",
    "\n",
    "    plot_data = new_f_clean\n",
    "#     if p==\"y\":\n",
    "#         ax.plot(time[start_len:], plot_data, 'k', label='FFT smoothening', linewidth=1.5)\n",
    "\n",
    "    plot_time = time[start_len:] \n",
    "    return plot_time, plot_data\n",
    "\n",
    "def plot_d(ax, time, data, c, l, alpha=1):\n",
    "    ax.plot(time, data, color=c, lw=2, label = l,alpha=alpha)\n",
    "\n",
    "\n",
    "def plot_one_bt(f, p,t=1):\n",
    "    print(f)\n",
    "    fs = f.split(\"-\")\n",
    "\n",
    "    pre = int(fs[1])\n",
    "    post = int(fs[2])\n",
    "    rtt = float(((pre+post)*2))/1000\n",
    "    ax = 0\n",
    "    if t==1:\n",
    "        data, time, retrans = get_window(f,\"n\",t)\n",
    "    elif t==2:\n",
    "        data, time, retrans, OOA, DA = get_window(f,\"n\",t)\n",
    "    if p == 'y':\n",
    "        fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "        for t in retrans :\n",
    "            plt.axvline(x = t, color = 'm',alpha=0.5)\n",
    "        if t == 2:\n",
    "            for t in OOA :\n",
    "                plt.axvline(x = t, color = 'k', lw=2)\n",
    "            for t in DA:\n",
    "                plt.axvline(x = t, color = 'g', lw=0.5, alpha = 0.5)\n",
    "        plot_d(ax,time,data, \"r\",\"Original\")\n",
    "    time, data = get_fft_smoothening(data, time, ax,rtt,\"y\")\n",
    "\n",
    "    #         plot_d(ax,time,data,\"b\",\"FFT Smoothened\" )\n",
    "#         print(len(time), len(data))\n",
    "    time, data = smoothen(time, data, rtt)\n",
    "#         print(len(time), len(data))\n",
    "    if p == 'y':\n",
    "        plot_d(ax, time, data, \"b\", \"Smoothened\",alpha=0.5)\n",
    "        ax.legend()\n",
    "#             plt.savefig(\"./plots/\"+f+\".png\")\n",
    "        plt.show()\n",
    "#     return time, data, grad_time, grad_data, rtt\n",
    "#     print(\"Black : OOA, Green : DA, Magenta : RP\")\n",
    "    return time, data, retrans, rtt \n",
    "\n",
    "\n",
    "def get_time_features(retrans,time,rtt):\n",
    "    time_thresh = 20*rtt\n",
    "    features = []\n",
    "    for i in range(1, len(retrans)):\n",
    "        if retrans[i]-retrans[i-1] >= time_thresh:\n",
    "            features.append([retrans[i-1], retrans[i]])\n",
    "    # add a feature that finished when the experiment ends\n",
    "    if time[-1] - retrans[-1] > 20*rtt :\n",
    "        features.append([retrans[-1],time[-1]])\n",
    "    return features\n",
    "\n",
    "def get_features(time, features):\n",
    "    left = 0\n",
    "    right = 0\n",
    "    feature_index = 0\n",
    "    in_feature = 0\n",
    "    index_features = []\n",
    "    while right < len(time) and feature_index < len(features): \n",
    "        if in_feature == 0 and time[right]>=features[feature_index][0]:\n",
    "            in_feature = 1\n",
    "            left = right\n",
    "        elif in_feature == 1 and time[right] > features[feature_index][1]:\n",
    "            in_feature = 0\n",
    "            index_features.append([left, right-1])\n",
    "            feature_index+=1\n",
    "        right+=1\n",
    "    if in_feature == 1:\n",
    "        index_features.append([left, right-1])\n",
    "    return index_features\n",
    "\n",
    "def get_plot_features(curr_file, p):\n",
    "    time, data, retrans, rtt = plot_one_bt(curr_file,p=p,t=1)\n",
    "    time_features = get_time_features(retrans,time,rtt)\n",
    "    features = get_features(time, time_features)    \n",
    "    if p == 'y':\n",
    "        fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "        plot_d(ax, time, data, \"b\", \"Smoothened\")\n",
    "        for ft in features : \n",
    "#             print(time[ft[1]]-time[ft[0]])\n",
    "            ax.plot(time[ft[0]:ft[1]+1], data[ft[0]:ft[1]+1], color = 'r')\n",
    "        plt.show()\n",
    "    return time, data, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "\n",
    "SHOW=True\n",
    "MULTI_GRAPH=False\n",
    "SMOOTHENING=False\n",
    "ONLY_STATS=False\n",
    "s_factor=0.9\n",
    "\n",
    "\n",
    "PKT_SIZE = 88\n",
    "\n",
    "\n",
    "'''\n",
    "TODO: \n",
    "o Add functionality where you only plot flows that send more than x bytes of data\n",
    "o Sort stats and graphs by flow size\n",
    "o Organize plots by flow size (larger flows have larger graphs)\n",
    "o Custom smoothening function\n",
    "'''\n",
    "\n",
    "fields=[\"time\", \"frame_time_rel\", \"tcp_time_rel\", \"frame_num\", \"frame_len\", \"ip_src\", \"src_port\", \"ip_dest\", \"dest_port\", \"tcp_len\", \"seq\", \"ack\"]\n",
    "\n",
    "class pkt:\n",
    "    contents=[]\n",
    "    def __init__(self, fields) -> None:\n",
    "        self.contents=[]\n",
    "        for f in fields:\n",
    "            self.contents.append(f)\n",
    "\n",
    "    def get(self, field):\n",
    "        return self.contents[fields.index(field)]\n",
    "        \n",
    "\n",
    "def process_flows(cc, dir,p=\"y\"):\n",
    "    name = dir+cc+\"-tcp.csv\"\n",
    "    with open(name) as csv_file:\n",
    "        print(\"Reading \"+name+\"...\")\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        total_bytes=0\n",
    "        '''\n",
    "        Flow tracking:\n",
    "        o Identify all packets that are either sourced from or headed to 100.64.0.2\n",
    "        o Group different flows by client's port\n",
    "        '''\n",
    "        flows={}\n",
    "        data_sent=0\n",
    "        # ACK and RTX measurement\n",
    "        ooa = set()\n",
    "        rp = set()\n",
    "        ooaCount=0\n",
    "        rpCount=0\n",
    "        daCount=0\n",
    "        backAck=0\n",
    "        for row in csv_reader:\n",
    "            reTx=0\n",
    "            \n",
    "            ooAck=0\n",
    "            dupAck=0\n",
    "            retPacket=0\n",
    "            \n",
    "            packet=pkt(row)\n",
    "            ackPkt=False\n",
    "            validPkt=False\n",
    "            if line_count==0:\n",
    "                # reject the header\n",
    "                line_count+=1\n",
    "                continue\n",
    "            if data_sent == 0 : \n",
    "                if \"100.64.0.\" in packet.get(\"ip_src\"):\n",
    "                    num = int(packet.get(\"ip_src\")[-1])\n",
    "                    if num%2==0:\n",
    "                        data_sent=1\n",
    "                        host_port=packet.get(\"ip_src\")\n",
    "                if \"100.64.0.\" in packet.get(\"ip_dest\"):\n",
    "                    num = int(packet.get(\"ip_dest\")[-1])\n",
    "                    if num%2==0:\n",
    "                        data_sent=1\n",
    "                        host_port=packet.get(\"ip_dest\")\n",
    "                if data_sent == 0:\n",
    "                    continue\n",
    "            if packet.get(\"ip_src\")==host_port and packet.get(\"frame_time_rel\")!='' and packet.get(\"ack\")!='': \n",
    "                # we care about this ACK packet\n",
    "                validPkt=True\n",
    "                ackPkt=True\n",
    "                port=packet.get(\"src_port\")\n",
    "                #PORTCHECK\n",
    "#                 if int(port) != 50468:\n",
    "#                     continue\n",
    "                if port not in flows:\n",
    "                    flows[port]={\"OOA\":[],\"DA\":[],\"max_seq\":0,\"loss_bif\":0,\"max_ack\":int(packet.get(\"ack\")),\"serverip\":packet.get(\"ip_dest\"), \"serverport\":packet.get(\"dest_port\"), \"act_times\":[],\"times\":[], \"windows\":[], \"cwnd\":[], \"bif\":0, \"last_ack\":0, \"last_seq\":0, \"pif\":0, \"drop\":[], \"next\":0, \"retrans\":[]}\n",
    "                else:\n",
    "                    # check for Out of Order Ack (OOA)\n",
    "                    if int(packet.get(\"ack\")) <= int(flows[port][\"max_ack\"]):\n",
    "                        if int(packet.get(\"ack\")) == backAck :\n",
    "                            dupAck = True\n",
    "                            flows[port][\"DA\"].append(float(packet.get(\"frame_time_rel\")))\n",
    "                        else :\n",
    "                            ooAck = True\n",
    "                            flows[port][\"OOA\"].append(float(packet.get(\"frame_time_rel\")))\n",
    "                        backAck = int(packet.get(\"ack\"))\n",
    "                    # update max_ack\n",
    "                    flows[port][\"max_ack\"] = max(flows[port][\"max_ack\"], int(packet.get(\"ack\")))\n",
    "                    if int(packet.get(\"seq\")) < flows[port][\"max_ack\"]:\n",
    "                        reTx += int(packet.get(\"tcp_len\"))\n",
    "#                     flows[port][\"times\"].append(float(packet.get(\"frame_time_rel\")) )\n",
    "                    \n",
    "            elif packet.get(\"ip_dest\")==host_port and packet.get(\"frame_time_rel\")!='' and packet.get(\"seq\")!='':\n",
    "                #we care about this Data packet\n",
    "                validPkt=True\n",
    "                port=packet.get(\"dest_port\")\n",
    "                #PORTCHECK\n",
    "#                 if int(port) != 50468:\n",
    "#                     continue\n",
    "                seq=int(packet.get(\"seq\"))\n",
    "                tcp_len=int(packet.get(\"tcp_len\"))\n",
    "                if port not in flows:\n",
    "                    flows[port]={\"OOA\":[],\"DA\":[],\"max_seq\":int(packet.get(\"seq\")),\"loss_bif\":0,\"max_ack\":0,\"serverip\":packet.get(\"ip_src\"), \"serverport\":packet.get(\"src_port\"),\"act_times\":[], \"times\":[], \"windows\":[], \"cwnd\":[], \"bif\":0, \"last_ack\":0, \"last_seq\":0, \"pif\":0, \"drop\":[], \"next\":0, \"retrans\":[]}\n",
    "                \n",
    "                else:\n",
    "                    flows[port][\"max_seq\"] = max(flows[port][\"max_seq\"], int(packet.get(\"seq\")))\n",
    "                \n",
    "                \n",
    "                if int(packet.get(\"seq\")) < flows[port][\"max_seq\"] :\n",
    "                    retPacket = True\n",
    "                    flows[port][\"retrans\"].append(flows[port][\"times\"][-1])\n",
    "                    \n",
    "            if validPkt==True:\n",
    "                bif = 0\n",
    "                normal_est_bif = int(flows[port][\"max_seq\"]) - int(flows[port][\"max_ack\"]) + PKT_SIZE#+ reTx\n",
    "                loss_est_bif = flows[port][\"loss_bif\"]\n",
    "                if ackPkt and dupAck and len(flows[port][\"windows\"]) > 10:\n",
    "                    if dupAck:\n",
    "                        # if we have received a duplicate ack then we need to reduce the bytes in flight by packet size\n",
    "                        # we also increase max ack to correct for the consolidated ack being sent later\n",
    "                        loss_est_bif = int(flows[port][\"windows\"][-1]) - PKT_SIZE\n",
    "                        flows[port][\"max_ack\"] += PKT_SIZE\n",
    "                        \n",
    "                        bif = min( normal_est_bif, loss_est_bif)\n",
    "                        if p == \"y\" :\n",
    "                            print(green+\"Duplicate Ack\",int(packet.get(\"ack\")),\"Max Ack\",flows[port][\"max_ack\"],\"BIF\",bif)\n",
    "                        \n",
    "#                     elif ooAck:\n",
    "#                         # first out of order ack that we have recieved not a duplicated ack\n",
    "#                         # the reason would be restransimitted packet so dont need to correct for this\n",
    "                        \n",
    "                elif ackPkt :\n",
    "                    loss_est_bif = normal_est_bif \n",
    "                    bif = normal_est_bif    \n",
    "                    if ooAck :\n",
    "                        ooaCount+=1\n",
    "                        if p == \"y\":\n",
    "                            print(red+\"Out of Order Ack\",int(packet.get(\"ack\")),\"Max Ack\",flows[port][\"max_ack\"],\"BIF\",normal_est_bif)\n",
    "                        ooa.add(int(packet.get(\"ack\")))\n",
    "                    else:\n",
    "                        if p == \"y\":\n",
    "                            print(black+\"Inorder Ack\",int(packet.get(\"ack\")),\"Max Seq\",flows[port][\"max_seq\"],\"BIF\",normal_est_bif)\n",
    "                else :\n",
    "                    bif = normal_est_bif\n",
    "                    if retPacket==True:\n",
    "                        rpCount+=1\n",
    "                        rp.add(int(packet.get(\"seq\")))\n",
    "                        if p == \"y\":\n",
    "                            print(pink+\"Retransmitted Packet\",int(packet.get(\"seq\")), \"Next\", flows[port][\"max_seq\"]+PKT_SIZE, \"BIF\",bif)\n",
    "                    else :\n",
    "                        if p == \"y\":\n",
    "                            print(blue+\"Inorder Packet\", int(packet.get(\"seq\")), \"Next\", flows[port][\"max_seq\"]+PKT_SIZE, \"BIF\",bif)\n",
    "                flows[port][\"loss_bif\"] = loss_est_bif\n",
    "                flows[port][\"windows\"].append( int(bif) )\n",
    "                flows[port][\"times\"].append( float(packet.get(\"frame_time_rel\")) )\n",
    "                \n",
    "#                 if ackPkt and dupAck and len(flows[port][\"windows\"]) > 10: # we have received atleast the first window\n",
    "# #                     if len(flows[port][\"windows\"]) < 2000: # print reTx in first 200 packets\n",
    "# #                         print( packet.get(\"ack\"), flows[port][\"max_ack\"])\n",
    "#                     loss_est_bif = int(flows[port][\"windows\"][-1]) - PKT_SIZE\n",
    "#                     flows[port][\"max_ack\"] += PKT_SIZE\n",
    "#                     bif = min( normal_est_bif, loss_est_bif )\n",
    "#                 elif ackPkt:\n",
    "#                     loss_est_bif = normal_est_bif \n",
    "#                     bif = normal_est_bif\n",
    "#                 else:\n",
    "#                     bif = normal_est_bif\n",
    "#                 flows[port][\"loss_bif\"] = loss_est_bif\n",
    "#                 flows[port][\"windows\"].append( int(bif) )\n",
    "            \n",
    "            \n",
    "            line_count+=1\n",
    "            total_bytes+=int(packet.get(\"frame_len\"))\n",
    "            #print(line_count, total_bytes)\n",
    "            \n",
    "#         print(\"total bytes processed:\", total_bytes/1000, \"KBytes for\", cc, \"(unlimited)\")\n",
    "        if p == \"y\":\n",
    "            print(\"Out of Order Acks\",len(ooa),\"Retransmitted Packets\",len(rp))\n",
    "            print(\"Count Out of Order Acks\",ooaCount,\"Retransmitted Packets\",rpCount)\n",
    "            print(\"OOA\",ooa,\"RP\",rp)\n",
    "    return flows\n",
    "\n",
    "def custom_smooth_function():\n",
    "    pass\n",
    "\n",
    "def get_flow_stats(flows):\n",
    "    num=len(flows.keys())\n",
    "    print(\"FLOW STATISTICS: \\nNumber of flows: \", num)\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print('%6s'%\"port\", '%15s'%\"SrcIP\", '%8s'%\"SrcPort\",  '%8s'%\"duration\",  '%8s'%\"start\",  '%8s'%\"end\", '%8s'%\"Sent (B)\", '%8s'%\"Recv (B)\",)\n",
    "    for k in flows.keys():\n",
    "        print('%6s'%k, '%15s'%flows[k][\"serverip\"], '%8s'%flows[k][\"serverport\"], '%8s'%str('%.2f'%(flows[k][\"times\"][-1]-flows[k][\"times\"][0])), '%8s'%str('%.2f'%flows[k][\"times\"][0]), '%8s'%str('%.2f'%flows[k][\"times\"][-1]), '%8s'%flows[k][\"last_seq\"], '%8s'%flows[k][\"last_ack\"])\n",
    "        #print(\"    * Flow \"+str(k)+\": \", flows[k][\"last_ack\"], \" \", flows[k][\"last_seq\"], \" bytes transfered.\")\n",
    "    return num\n",
    "\n",
    "def run(files):\n",
    "    flows = {}\n",
    "    for f in files:\n",
    "        algo_cc=f\n",
    "        #Get the data for all the flows\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"opening trace ../measurements/\"+algo_cc+\".csv...\")\n",
    "        flows = process_flows(algo_cc, \"./Nebby/measurements-new-btl/50-200-2-60/\")\n",
    "        #decide on final graph layout\n",
    "        num = get_flow_stats(flows)\n",
    "\n",
    "        if ONLY_STATS:\n",
    "            sys.exit()\n",
    "\n",
    "        if num==1:\n",
    "            MULTI_GRAPH=False\n",
    "        #grid size\n",
    "        if MULTI_GRAPH:\n",
    "            size=(0,0)\n",
    "            grids={1:(2,2), 2:(2,2), 4:(2,2), 6:(2,3), 9:(3,3), 12:(3,4), 15:(3,5), 16:(4,4), 20:(5,4), 24:(6,4), 30:(6,5), 36:(6,6), 40:(8,5), 42:(8,7), 49:(7,7)}\n",
    "            g=num\n",
    "            while g<=49 and g not in grids:\n",
    "                g+=1\n",
    "            if g in grids.keys():\n",
    "                size=grids[g]\n",
    "            else:\n",
    "                size=grids[49]  \n",
    "            fig, axs = plt.subplots(size[0], size[1])\n",
    "            for i in range(size[0]):\n",
    "                for j in range(size[1]):\n",
    "                    #axs[i][j].legend(loc=\"lower right\")\n",
    "                    if i==size[0]-1:\n",
    "                        axs[i][j].set_xlabel(\"Time (s)\")\n",
    "                    if j==0:\n",
    "                        axs[i][j].set_ylabel(\"Bytes in flight\")\n",
    "        else:\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Bytes in flight\")\n",
    "        counter=0\n",
    "        for port in flows.keys():\n",
    "            if MULTI_GRAPH:  \n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].scatter(flows[port][\"times\"], flows[port][\"windows\"], color=\"#858585\")\n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].plot(flows[port][\"times\"], flows[port][\"windows\"], label=str(port), linestyle=\"solid\")\n",
    "            else:\n",
    "                plt.plot(flows[port][\"times\"], flows[port][\"windows\"], label=str(port), linestyle=\"solid\")\n",
    "                plt.scatter(flows[port][\"times\"], flows[port][\"windows\"], color=\"#858585\")\n",
    "            counter+=1\n",
    "        if MULTI_GRAPH:\n",
    "            counter=0\n",
    "            for port in flows.keys():\n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].legend()\n",
    "                counter+=1\n",
    "        else:\n",
    "            plt.legend()\n",
    "        if MULTI_GRAPH:\n",
    "            fig.set_size_inches(16, 12)\n",
    "        if SHOW:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(\"../logs/results/\"+algo_cc+\".png\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
    "    return flows\n",
    "\n",
    "\n",
    "def get_window(f,p,t=1):\n",
    "    algo_cc = f\n",
    "    flows = process_flows(algo_cc, \"../../website_measurements/singapore/top1k/\",p=p)\n",
    "#     flows = process_flows(algo_cc, \"../measurements/m/\",p=p)\n",
    "#     flows = process_flows(algo_cc, \"./Nebby/measurements/\",p=p)    \n",
    "#     flows = process_flows(algo_cc, \"./Nebby/measurements-new-btl/50-200-2-60/\",p=p)\n",
    "#     flows = process_flows(algo_cc, \"./Nebby/measurements-100-150/\",p=p)\n",
    "    params = algo_cc.split(\"-\")\n",
    "    data = []\n",
    "    time = []\n",
    "    drops = []\n",
    "    retrans = []\n",
    "    OOA = []\n",
    "    DA = []\n",
    "    use_port = 0\n",
    "    maxx = 0\n",
    "    print(\"All Ports : \", flows.keys())\n",
    "    for port in flows.keys():\n",
    "        if len(flows[port]['windows']) > maxx:\n",
    "            maxx = len(flows[port]['windows'])\n",
    "            use_port = port\n",
    "    print(\"Port\",use_port)\n",
    "    data = flows[use_port]['windows']\n",
    "    time = flows[use_port]['times']\n",
    "    retrans = flows[use_port]['retrans']\n",
    "    OOA = flows[use_port]['OOA']\n",
    "    DA = flows[use_port]['DA']\n",
    "    if p == \"y\":\n",
    "        plt.plot(time, data)\n",
    "#     time_index = len(time)-1\n",
    "#     for index in range(len(flows[use_port]['times'])-1):\n",
    "#         if flows[use_port]['times'][index+1] - flows[use_port]['times'][index] > :\n",
    "#             time_index = index\n",
    "#     time_last = flows[use_port]['times'][time_index]\n",
    "#     data = data[:time_index+1]\n",
    "#     time = time[:time_index+1]\n",
    "    if t==2:\n",
    "        return data, time, retrans, OOA, DA\n",
    "    if t==1:\n",
    "        return data, time, retrans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
