{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688523ca",
   "metadata": {},
   "source": [
    "# Working with mean and standard deviation\n",
    "## Get the euclidean distance between the model cc cubic polynomial, and find acceptance probability. - Statistical metric for this. What is the probability that a point is a part of the normal distribution. \n",
    "### I model the a,b,c,d as a multimodel normal distrbution. So I have a list of these normal distributions, and then I get the probability that this particular data point is from this distribuition. \n",
    "### This is the theory for a *guassian mixture model*, except here I know the clusters from before.\n",
    "\n",
    "#### We would look only at the starting feature - the first feature\n",
    "#### We would look at all a,b,c,d firsty and then see for a,b,c as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d2eed",
   "metadata": {},
   "source": [
    "##### Lets see what is the value for the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a867a6f",
   "metadata": {},
   "source": [
    "#### Testing the accuracy of model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df3ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals, new_vals, cc_gaussian_params = train(var,s=1,e=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_test_data(var, s=11, e=20):\n",
    "    cc_coeff_test = getCCcoeff(var,11,20)\n",
    "    vals_test, new_vals_test = getCoeff(cc_coeff_test, \"\", p=\"n\")\n",
    "    return vals_test, new_vals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a1b20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals_test, new_vals_test = collect_test_data(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(vals_test, cc_gaussian_param):\n",
    "    acc_m = {}\n",
    "    for cc in vals_test:\n",
    "        if cc not in acc_m :\n",
    "            acc_m[cc] = []\n",
    "        data = vals_test[cc][1]\n",
    "        for curr in data:\n",
    "            p_dense = getPDensity(curr, cc_gaussian_params)\n",
    "            acc_m[cc].append(p_dense)\n",
    "    top = {}\n",
    "    error = {}\n",
    "    for cc in acc_m :\n",
    "        top[cc] = {}\n",
    "        ind = 0\n",
    "        for item in acc_m[cc]:\n",
    "            ccs = np.array(list(item.keys()))\n",
    "            vals = np.array(list(item.values()))\n",
    "            if min(vals) == 0:\n",
    "                if max(vals) < 1 : \n",
    "                    #This is an arbitrary constant\n",
    "                    if cc not in error :\n",
    "                        error[cc] = []\n",
    "                        error[cc].append(ind)\n",
    "                        ind+=1\n",
    "                        continue        \n",
    "            new_vals = (vals-min(vals))/(max(vals)-min(vals))\n",
    "            index_list =list(np.argsort(new_vals))\n",
    "            index_list.reverse()\n",
    "            cc_list = [ccs[i] for i in index_list]\n",
    "            vals_list = [vals[i] for i in index_list]\n",
    "            new_vals_list = [new_vals[i] for i in index_list]\n",
    "            top[cc][ind] = {}\n",
    "            top[cc][ind]['cc'] = cc_list[0:3]\n",
    "            top[cc][ind]['vals'] = vals_list[0:3]\n",
    "            top[cc][ind]['new_vals'] = new_vals_list[0:3]\n",
    "            ind+=1\n",
    "    return acc_m, top, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m, top, error = get_test_accuracy(vals_test, cc_gaussian_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(top):\n",
    "    for cc in top :\n",
    "        print()\n",
    "        print(cc)\n",
    "        print()\n",
    "        for i in top[cc]:\n",
    "            print(i)\n",
    "            for d in top[cc][i]:\n",
    "                print(top[cc][i][d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27174bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_top_predictions(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(top):\n",
    "    acc_data = {}\n",
    "    for cc in top :\n",
    "        acc_data[cc] = {}\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        for item in top[cc]:\n",
    "            curr = top[cc][item]\n",
    "            for i in range(min(3,len(curr['new_vals']))):\n",
    "                if curr['new_vals'][i] > 0.90 :\n",
    "                    if curr['cc'][i] not in acc_data[cc]:\n",
    "                        acc_data[cc][curr['cc'][i]] = 0\n",
    "                    acc_data[cc][curr['cc'][i]] += 1\n",
    "                    if curr['cc'][i] == cc :\n",
    "                        correct += 1\n",
    "                    else : \n",
    "                        incorrect += 1\n",
    "        incorrect += 10 - len(top[cc])\n",
    "        acc_data[cc]['correct'] = correct\n",
    "        acc_data[cc]['incorrect'] = incorrect\n",
    "        acc_data[cc]['accuracy'] = (correct*100)/(correct+incorrect)\n",
    "    return acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fa7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = getAccuracy(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51582d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(acc_data):\n",
    "    for cc in acc_data:\n",
    "        new_dict = acc_data[cc]\n",
    "        print()\n",
    "        print(cc)\n",
    "        print(\"Accuracy :\", round(new_dict['accuracy'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48391301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all once \n",
    "vals, new_vals, cc_gaussian_params = train(var,s=1,e=10)\n",
    "vals_test, new_vals_test = collect_test_data(var,s=10,e=20)\n",
    "acc_m, top, error = get_test_accuracy(vals_test, cc_gaussian_params)\n",
    "acc_data = getAccuracy(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4463d0",
   "metadata": {},
   "source": [
    "### Sample - 500 and Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(acc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0d2f4",
   "metadata": {},
   "source": [
    "### Sample - 500 and Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(acc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dd9ab",
   "metadata": {},
   "source": [
    "## Trained on more data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf634f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84978df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results = getRed(['cubic-1-0-50-1000-2'], p='y')\n",
    "# error\n",
    "for cc in error :\n",
    "    print(cc)\n",
    "    for i in range(1,11):\n",
    "        print(i)\n",
    "        print()\n",
    "        file = cc + \"-\" + str(i) + '-0-50-1000-2'\n",
    "        res = getRed([file], p='y')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add5eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1849b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47c43cc",
   "metadata": {},
   "source": [
    "## Training for model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b55998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(var,s=1,e=10):\n",
    "    cc_coeff = getCCcoeff(var,s=s,e=e)\n",
    "    vals, new_vals = getCoeff(cc_coeff, \"\", p=\"n\")\n",
    "    cc_gaussian_params = getGaussianParams(vals)\n",
    "    return vals, new_vals, cc_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaussianParams(vals):\n",
    "    cc_gaussian_params = {}\n",
    "    for cc in vals :\n",
    "        # Taking the first feature only\n",
    "        data = vals[cc][1]\n",
    "        n = 0\n",
    "        cc_coeff_mean = np.mean(data,axis=0)\n",
    "        coeff_var = np.cov(data, rowvar=0)\n",
    "        iden = np.identity(len(coeff_var))\n",
    "        cc_coeff_var = coeff_var * iden\n",
    "        cc_gaussian_params[cc] = {\n",
    "            'mean' : cc_coeff_mean,\n",
    "            'covar' : cc_coeff_var\n",
    "        }\n",
    "    return cc_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "def getPDensity(curr, cc_gaussian_params):\n",
    "    prob = {}\n",
    "    for cc in cc_gaussian_params:\n",
    "        mn = cc_gaussian_params[cc]['mean']\n",
    "        covar = cc_gaussian_params[cc]['covar']\n",
    "        curr_p = mvn.pdf(curr,mean=mn, cov=covar)\n",
    "        prob[cc]=curr_p\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCCcoeff(var,s=1,e=10,p=\"n\"):\n",
    "    cc_coeff = {}\n",
    "    for v in var :\n",
    "        files = [v + \"-\" + str(i) + \"-0-50-1000-2\" for i in range(s,e+1)]\n",
    "        cc_mp, lin, quad, cub, errors = get_feature_degree(files,ss=524,p=p)\n",
    "        coeff = getCC(files, cc_mp,p=p)\n",
    "        cc_coeff[v] = coeff[v]\n",
    "        #     getRed(files,p=\"y\")\n",
    "    return cc_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_degree(['cubic-1-0-50-1000-2'],ss=524,p=\"n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697df34b",
   "metadata": {},
   "source": [
    "#### Below is testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_gaussian_params = getGaussianParams(vals)\n",
    "prob = getPDensity(vals['bic'][1][1], cc_gaussian_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53810dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cc in vals :\n",
    "    data = vals[cc][1]\n",
    "    cc_coeff_mean = np.mean(data,axis=0)\n",
    "    cc_coeff_var = np.cov(data, rowvar=0)\n",
    "    print(cc)\n",
    "    print(cc_coeff_mean)\n",
    "    print(cc_coeff_var)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e446f81",
   "metadata": {},
   "source": [
    "# Getting a horizontal graph with ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb35b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gantt = {}\n",
    "ytick = []\n",
    "for cc in new_vals :\n",
    "    ytick.append(cc)\n",
    "    for ft in range(1,4):\n",
    "        if ft not in gantt:\n",
    "            gantt[ft] = {}\n",
    "        if ft not in new_vals[cc]:\n",
    "            coeff = {'a':[0],'b':[0],'c':[0],'d':[0]}\n",
    "        else :\n",
    "            coeff = new_vals[cc][ft]\n",
    "        for cf in coeff : \n",
    "            if cf not in gantt[ft]:\n",
    "                gantt[ft][cf] = []\n",
    "            mn = mean(coeff[cf])\n",
    "            std = pstdev(coeff[cf])\n",
    "#             gantt[ft][cf].append((min(coeff[cf]), max(coeff[cf])-min(coeff[cf])))\n",
    "            gantt[ft][cf].append((mn-std, 2*std))\n",
    "#             gantt[ft][cf].append((0,mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gantt_chart(ax,x,ytick):\n",
    "    ytick_points=[]\n",
    "    new_ytick = []\n",
    "    start = 0.3\n",
    "    index_list =  [i[0] for i in sorted(enumerate(x), key=lambda x:x[1][0])]\n",
    "    print(x)\n",
    "    print(index_list)\n",
    "    for ind in index_list:\n",
    "        ax.broken_barh(xranges=[x[ind]], yrange=(start,0.5))\n",
    "        new_ytick.append(ytick[ind])\n",
    "        ytick_points.append(start)\n",
    "        start+=1\n",
    "    ax.set_yticks(ytick_points)\n",
    "    ax.set_yticklabels(new_ytick)\n",
    "    ax.set_title(coeff)\n",
    "    plt.show()\n",
    "#     ax.set_yticklabels(map(textwrap_func, ax.get_yticklabels()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f0ebe",
   "metadata": {},
   "source": [
    "## Min and Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4acd718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index in gantt:\n",
    "    print(\"index of feature \", index)\n",
    "    for coeff in gantt[index]:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        make_gantt_chart(ax,gantt[index][coeff],ytick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb66fb6",
   "metadata": {},
   "source": [
    "## Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d1b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index in gantt:\n",
    "    print(\"index of feature \", index)\n",
    "    for coeff in gantt[index]:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        make_gantt_chart(ax,gantt[index][coeff],ytick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb7075",
   "metadata": {},
   "source": [
    "## Mean from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78675998",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in gantt:\n",
    "    print(\"index of feature \", index)\n",
    "    for coeff in gantt[index]:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        make_gantt_chart(ax,gantt[index][coeff],ytick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CC\n",
    "#   - 1 Index\n",
    "#   - coeff - all the coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea6cd2",
   "metadata": {},
   "source": [
    "## Running the same thing on 10 experiments to understand the distribution of the coeff for particular algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['cubic','reno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a175e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_coeff = getCCcoeff(var,s=11,e=19,p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a106591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = {}\n",
    "for cc in cc_coeff:\n",
    "    coeff = cc_coeff[cc]\n",
    "    if cc not in vals :\n",
    "        vals[cc] = {}\n",
    "    for trace in coeff:\n",
    "        i = 1\n",
    "        for feature in trace:\n",
    "            if i not in vals[cc]:\n",
    "                vals[cc][i] = []\n",
    "            vals[cc][i].append(feature)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc200e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cc in vals:\n",
    "    items = vals[cc]\n",
    "    for i in items :\n",
    "        print(i)\n",
    "        for co in items[i]:\n",
    "            print(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9138f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getCoeff(cc_coeff, gcc=\"\", p='y'):\n",
    "    vals = {}\n",
    "    degree = 0\n",
    "    for cc in cc_coeff:\n",
    "        coeff = cc_coeff[cc]\n",
    "        if cc not in vals :\n",
    "            vals[cc] = {}\n",
    "        for trace in coeff:\n",
    "            i = 1\n",
    "            for feature in trace:\n",
    "                if i not in vals[cc]:\n",
    "                    vals[cc][i] = []\n",
    "                degree = len(feature)\n",
    "                vals[cc][i].append(feature)\n",
    "                i+=1\n",
    "    new_vals = {}\n",
    "    coe = ['a','b','c','d']\n",
    "    for cc in vals:\n",
    "        new_vals[cc] = {}\n",
    "        for i in vals[cc]:\n",
    "            new_vals[cc][i] = {}\n",
    "            c_val = {'a':[],'b':[],'c':[],'d':[]}\n",
    "            for ft in vals[cc][i]:\n",
    "                for x in range(degree):\n",
    "                    c_val[coe[x]].append(ft[x])\n",
    "            for x in range(degree):\n",
    "                new_vals[cc][i][coe[x]] = c_val[coe[x]]\n",
    "    if p == 'y':\n",
    "        for cc in new_vals : \n",
    "            print(cc)\n",
    "            if gcc != \"\" :\n",
    "                if gcc != cc :\n",
    "                    continue\n",
    "            print(cc)\n",
    "            for i in new_vals[cc] :\n",
    "                print(\"Feature Index \", i)\n",
    "                for c in coe :\n",
    "                    x = new_vals[cc][i][c]\n",
    "                    mn = mean(x)\n",
    "                    std = pstdev(x)\n",
    "                    plt.hist(x,bins=10)\n",
    "                    plt.vlines(mn+std,0,3,color='r')\n",
    "                    plt.vlines(mn-std,0,3,color='r')\n",
    "                    plt.title(str(i) + \" \" + c)\n",
    "                    plt.show()\n",
    "                    plt.show()\n",
    "#                 mn = mean(b)\n",
    "#                 std = pstdev(b)\n",
    "#                 plt.hist(b,bins=10)\n",
    "#                 plt.vlines(mn+std,0,3,color='r')\n",
    "#                 plt.vlines(mn-std,0,3,color='r')\n",
    "#                 plt.title(str(i) + \" b\")\n",
    "#                 plt.show()\n",
    "#                 mn = mean(c)\n",
    "#                 std = pstdev(c)\n",
    "#                 plt.hist(c,bins=10)\n",
    "#                 plt.vlines(mn+std,0,3,color='r')\n",
    "#                 plt.vlines(mn-std,0,3,color='r')\n",
    "#                 plt.title(str(i) + \" c\")\n",
    "#                 plt.show()\n",
    "#                 mn = mean(d)\n",
    "#                 std = pstdev(d)\n",
    "#                 plt.hist(d,bins=10)\n",
    "#                 plt.vlines(mn+std,0,3,color='r')\n",
    "#                 plt.vlines(mn-std,0,3,color='r')\n",
    "#                 plt.title(str(i) + \" d\")\n",
    "    return vals, new_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac82abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals, new_vals = getCoeff(cc_coeff, \"\", p=\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11822ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals, new_vals = getCoeff(cc_coeff, \"cubic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1925a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb68c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [\"cubic\", \"reno\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca64770",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"bic dctcp highspeed htcp illinois lp nv scalable vegas veno westwood yeah cubic reno\"\n",
    "#\"cdg hybla\"\n",
    "var = var.split(\" \")\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "def get_degree(time,data, p=\"n\", check=50):\n",
    "    p = []\n",
    "    mse_l = []\n",
    "    time -= min(time)\n",
    "    data -= min(data)\n",
    "    data /= 1000\n",
    "    p1 = np.polyfit(time, data, 1)\n",
    "    p.append(p1)\n",
    "    fit_l = np.polyval(p1, time)\n",
    "    \n",
    "    p2 = np.polyfit(time, data, 2)\n",
    "    p.append(p2)\n",
    "    fit_q = np.polyval(p2, time)\n",
    "    \n",
    "    p3 = np.polyfit(time, data, 3)\n",
    "    p.append(p3)\n",
    "    fit_c = np.polyval(p3, time)\n",
    "    mse_l.append(mse(data, fit_l))\n",
    "    mse_l.append(mse(data, fit_q))\n",
    "    mse_l.append(mse(data, fit_c))\n",
    "    if p =='y':\n",
    "        print(\"1 \", p1, \"MSE \", mse(data, fit_l))\n",
    "        print(\"2 \", p2, \"MSE \", mse(data, fit_q))\n",
    "        print(\"3 \", p3, \"MSE \", mse(data, fit_c))\n",
    "        plt.plot(time, data)\n",
    "        plt.plot(time, fit_l)\n",
    "        plt.plot(time, fit_q)\n",
    "        plt.plot(time, fit_c)\n",
    "        plt.show()\n",
    "    check = check\n",
    "    if mse_l[1] < 0.50*mse_l[0] :\n",
    "        if mse_l[2] < 0.50*mse_l[1] :\n",
    "            degree = 3\n",
    "        else :\n",
    "            degree = 2\n",
    "    else :\n",
    "        degree = 1\n",
    "#         if 0.5*(mse_l[0]-mse_l[1]) > mse_l[1]-mse_la :\n",
    "#         a[2] :\n",
    "#             degree = 1\n",
    "#         else:\n",
    "#             degree = 2\n",
    "#     else:\n",
    "#         degree = 0\n",
    "#     if mse_l[2#     for i in 1](0,len(mse_l)-1):\n",
    "#         diff = abs(mse_l[len(mse_l)-1] - mse_l[i])\n",
    "#         perc = (diff/mse_l[len(mse_l)-1])*100\n",
    "#         if perc < check :\n",
    "#             return i+1,p[i], mse_l\n",
    "#     return degree, p[degree-1], mse_l\n",
    "#     return 2, p[1], mse_l\n",
    "    return 3,p[2], mse_l\n",
    "# get_degree(time, data)\n",
    "from statistics import mean \n",
    "def get_feature_degree(files,ss=125,p='n'):\n",
    "    print(ss)\n",
    "    results = getRed(files,ss,p=p)\n",
    "    errors = []\n",
    "    mp = {}\n",
    "    lin = {}\n",
    "    quad = {}\n",
    "    cub = {}\n",
    "    cc_mp = {}\n",
    "    for item in results :\n",
    "        for ele in list(item.keys()):\n",
    "            name_list = ele.split(\"_\")\n",
    "            cc = name_list[0]\n",
    "            name = name_list[0] + name_list[-1]\n",
    "            if \"data\" in ele :\n",
    "                curr_data = np.array(item[ele])\n",
    "            if \"time\" in ele :\n",
    "                curr_time = np.array(item[ele])\n",
    "        degree, coeff, error_item = get_degree(curr_time, curr_data, check=25)\n",
    "        mp[name] = {'d':degree, 'coeff':coeff, 'error':error_item, 'data':curr_data, 'time':curr_time}\n",
    "        if cc not in cc_mp :\n",
    "            cc_mp[cc] = []\n",
    "        cc_mp[cc].append(mp[name])\n",
    "        if degree == 1 :\n",
    "            lin[name] = mp[name]\n",
    "        if degree == 2:\n",
    "            quad[name] = mp[name]\n",
    "        if degree == 3:\n",
    "            cub[name] = mp[name]\n",
    "        error_item.append(name)\n",
    "        error_item.append(degree)\n",
    "        errors.append(error_item)\n",
    "    return cc_mp, lin, quad, cub, errors\n",
    "\n",
    "def getCC(files,cc_mp, s=100, p=\"n\"):\n",
    "    # experiment change start\n",
    "    cc_coeff = {}\n",
    "    for file in files :\n",
    "#         file = v + \"-0-50-1000-2\"\n",
    "        curr_file = [file]\n",
    "        cc = file.split(\"-\")[0]\n",
    "        version = file.split(\"-\")[1]\n",
    "        v = cc+\"-\"+version\n",
    "        if cc not in cc_coeff:\n",
    "            cc_coeff[cc] = []\n",
    "    # experiment change end\n",
    "        features, time, data = get_new_grad(curr_file, 'n')\n",
    "        count = 0\n",
    "        temp = []\n",
    "        n = math.ceil(float(len(cc_mp[v]))/3)\n",
    "        for item in cc_mp[v]:\n",
    "            time = item['time']\n",
    "            data = item['data']\n",
    "#             time -= min(time)\n",
    "#             data -= min(data)\n",
    "#             data /= 1000\n",
    "            deg = item['d']\n",
    "            temp.append(item['coeff'])    \n",
    "            xlim = 0\n",
    "            ylim = 0\n",
    "            for i in [0.5,1,2,4,8,16]:\n",
    "                if time[-1]<i:\n",
    "                    xlim = i\n",
    "                    break\n",
    "            for i in [0.5,1,2,4,8,16]:\n",
    "                if data[-1]<i:\n",
    "                    ylim = i\n",
    "                    break\n",
    "#             if data[-1] < 1 :\n",
    "            lim = max(xlim, ylim)\n",
    "            names = ['Linear', \"Quadratic\", \"Cubic\"]\n",
    "            count+=1\n",
    "            if p == 'y':\n",
    "                plt.plot(time,data)\n",
    "                plt.plot(time, np.polyval(item['coeff'],time))\n",
    "                plt.xlim(0,lim)\n",
    "                plt.ylim(0,lim)\n",
    "                plt.title(str(count)+\" \" + names[deg-1])\n",
    "                plt.show()\n",
    "                plt.figure().set_figwidth(4)\n",
    "                plt.figure().set_figheight(2)\n",
    "                plt.bar([i for i in range(1,deg+2)], item['coeff'])\n",
    "                plt.show()\n",
    "                plt.figure().set_figwidth(4)\n",
    "                plt.figure().set_figheight(2)\n",
    "                plt.bar([1,2,3], item['error'][0:3], tick_label=['lin', 'quad', 'cubic'])\n",
    "                plt.show()\n",
    "        cc_coeff[cc].append(temp)\n",
    "    return cc_coeff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c985d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "def lower_bound(arr, target):\n",
    "    index = bisect.bisect_left(arr, target)\n",
    "    return index\n",
    "\n",
    "def sample_data_time(time, data, s, m):\n",
    "    curr_time, curr_data = adjust(time, data, 0.10)\n",
    "    tp = curr_time[len(curr_time)-1] - curr_time[0]\n",
    "    step = tp/m\n",
    "    samp_time = [curr_time[0] + i*step for i in range(m)]\n",
    "    x = np.random.uniform(0,math.pi,s)\n",
    "    tr_x = np.cos(x)\n",
    "    tr_x += 1\n",
    "    tr_x *= (m-1)/2\n",
    "    ind = [int(round(e, 0)) for e in tr_x]\n",
    "    sort_ind = sorted(ind)\n",
    "    tr_time = [samp_time[i] for i in sort_ind]\n",
    "\n",
    "    new_time = []\n",
    "    new_data = []\n",
    "    for t in tr_time :\n",
    "        i = lower_bound(curr_time, t)\n",
    "        temp_t = 0\n",
    "        temp_d = 0\n",
    "        if round(t,6) == round(curr_time[i],6):\n",
    "            temp_t = curr_time[i]\n",
    "            temp_d = curr_data[i]\n",
    "        else : \n",
    "            if i == 0 :\n",
    "                temp_t = curr_time[i]\n",
    "                temp_d = curr_data[i]\n",
    "            elif i == len(curr_time)-1 :\n",
    "                temp_t = curr_time[i]\n",
    "                temp_d = curr_data[i]\n",
    "            else :\n",
    "                temp_t = (curr_time[i-1] + curr_time[i])/2\n",
    "                temp_d = (curr_data[i-1] + curr_data[i])/2\n",
    "        new_time.append(temp_t)\n",
    "        new_data.append(temp_d)\n",
    "#     return curr_time, curr_data\n",
    "    return new_time, new_data\n",
    "\n",
    "def adjust(time, data, m=0.25):\n",
    "    control = 100000;\n",
    "    rtt=0.1\n",
    "    for t in range(len(time)) :\n",
    "        if time[t]-time[0] > 5*rtt:\n",
    "            control = t; \n",
    "            break\n",
    "    l = min(t,int(m*len(time)))\n",
    "    e = int(len(time)-l)\n",
    "    start = max(data.index(min(data[0:l])),data.index(max(data[0:l])))\n",
    "    end = min(data.index(max(data[e:])), data.index(min(data[e:])))\n",
    "    new_time = time[start:end+1]\n",
    "    new_data = data[start:end+1]\n",
    "    return new_time, new_data\n",
    "\n",
    "# Taking 100 as the threshold is fine \n",
    "# Now we have to see how the graphs look if we use it. \n",
    "# var = [\"reno\", \"cubic\", \"bbr\"]\n",
    "def getRed(files,ss=125,p=\"y\"):\n",
    "    results = []\n",
    "    rtt = 0.1\n",
    "    thresh = 5*rtt\n",
    "    # experiment change start\n",
    "    for file in files :\n",
    "#         file = v + \"-0-50-1000-2\"\n",
    "    # experiment change end    \n",
    "        f_split = file.split(\"-\")\n",
    "        v = f_split[0] + \"-\" + f_split[1]\n",
    "        curr_file = [file]\n",
    "        features, time, data = get_new_grad(curr_file, p)\n",
    "        count = 0\n",
    "        for ft in features : \n",
    "            if ft[2]==0:\n",
    "                time_period = time[ft[1]] - time[ft[0]]\n",
    "                if time_period >= thresh:\n",
    "#                     print(time[ft[0]], time[ft[1]])\n",
    "                    curr_time = time[ft[0]:ft[1]+1]\n",
    "                    curr_data = data[ft[0]:ft[1]+1]\n",
    "                    tr_time, tr_data = sample_data_time(curr_time, curr_data, ss, 1000)\n",
    "                    tr_time_pd = pd.DataFrame(tr_time)\n",
    "                    tr_data_pd = pd.DataFrame(tr_data)\n",
    "                    tr_time = list(tr_time_pd.rolling(25, center=True).mean().dropna()[0])\n",
    "                    tr_data = list(tr_data_pd.rolling(25, center=True).mean().dropna()[0])\n",
    "#                     print(tr_time)\n",
    "#                     print(tr_time_t)\n",
    "#                     print(tr_data)\n",
    "#                     print(tr_data_t)\n",
    "                    print(\"Data and Time Length \", len(tr_data), len(tr_time))\n",
    "                    if p == \"y\" :\n",
    "                        plt.plot(curr_time, curr_data, c='b', alpha = 0.5, lw = 5)\n",
    "                        plt.plot(tr_time, tr_data, c='r', alpha = 1)\n",
    "                        plt.scatter(tr_time, tr_data, c='k')\n",
    "        #                 plt.scatter(tr_time, tr_data, c='r', s=10)\n",
    "                        plt.title(v)\n",
    "                        plt.show()\n",
    "#                     print(\"Data Difference : \" + str(tr_data[-1]-tr_data[0]))\n",
    "#                     print(\"Time Difference : \" + str(tr_time[-1]-tr_time[0]))\n",
    "                    results.append({v+\"_\"+\"data\"+\"_\"+str(count):tr_data, v+\"_\"+\"time\"+\"_\"+str(count):tr_time})\n",
    "                    count+=1\n",
    "    return results\n",
    "# results = getRed(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f13972",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af59e869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,31):\n",
    "#     results = getRed(['reno-' + str(i) + '-0-50-1000-2'],ss=524, p='y')\n",
    "    plot_one_bt(['cubic-' + str(i) + '-0-50-1000-2'], p= \"y\")\n",
    "#     get_new_grad(['reno-' + str(i) + '-0-50-1000-2'], p= \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.fft import irfft\n",
    "import numpy as np\n",
    "import statistics\n",
    "from statistics import mean, pstdev\n",
    "import pandas as pd\n",
    "\n",
    "def smoothen(time, data, rtt):\n",
    "    # Smoothening \n",
    "    left = 0\n",
    "    right = 0\n",
    "    run_sum = 0\n",
    "    avg_data = []\n",
    "    new_time = []\n",
    "    roll_time = time\n",
    "    roll_data = data\n",
    "#     while(time[right]-time[left] < float(rtt)/2):\n",
    "#         avg_data.append(data[right])\n",
    "#         new_time.append(time[right])\n",
    "#         right+=1\n",
    "#     roll_data = pd.DataFrame(data)\n",
    "#     roll_time = pd.DataFrame(time)\n",
    "#     roll_data =roll_data.rolling(10,center=True).mean().dropna()\n",
    "#     roll_time =roll_time.rolling(10,center=True).mean().dropna()\n",
    "#     roll_data = list(roll_data[0])\n",
    "#     roll_time = list(roll_time[0])\n",
    "    while right < len(roll_time):\n",
    "        while(right < len(roll_time) and (roll_time[right]-roll_time[left] < 2*rtt)):\n",
    "            run_sum+=roll_data[right]\n",
    "            right+=1\n",
    "        new_time.append(float(roll_time[right-1]+roll_time[left])/2)\n",
    "        avg_data.append(float(run_sum)/(right-left))\n",
    "        run_sum-=roll_data[left]\n",
    "        left+=1\n",
    "    #experiment change start\n",
    "#     avg_data = pd.DataFrame(avg_data)\n",
    "#     new_time = pd.DataFrame(new_time)\n",
    "#     avg_data =avg_data.rolling(50,center=True).mean().dropna()\n",
    "#     new_time =new_time.rolling(50, center=True).mean().dropna()\n",
    "#     avg_data = list(avg_data[0])\n",
    "#     new_time = list(new_time[0])\n",
    "#     print(avg_data)\n",
    "#     print(new_time)\n",
    "    #experiment end\n",
    "#     right-=1\n",
    "#     prev = right\n",
    "#     while(time[right] - time[prev] < float(rtt)/2):\n",
    "#         prev-=1\n",
    "#     prev+=1\n",
    "#     for i in range(prev, right+1):\n",
    "#         avg_data.append(data[i])\n",
    "#         new_time.append(time[i])\n",
    "#     print(len(data), len(avg_data), len(new_time))\n",
    "#     avg_data = n_data.rolling(window=60, center=True).mean()\n",
    "#     new_time = time\n",
    "#     for i in range(30):\n",
    "#         avg_data[0][i] = data[i]\n",
    "#     for i in range(-1, -30, -1):\n",
    "#         avg_data[0][len(data) + i] = data[len(data) + i]\n",
    "#     ans_data = avg_data[0]\n",
    "#     Smoothen function works well.\n",
    "    return new_time, avg_data\n",
    "#     return roll_time, roll_data\n",
    "\n",
    "def get_fft(data):\n",
    "    n = len(data)\n",
    "    data_step = 0.002\n",
    "    yf = rfft(data)\n",
    "    xf = rfftfreq(n,data_step)\n",
    "    return yf,xf\n",
    "\n",
    "def get_fft_smoothening(ax,f,norm,rtt,p):\n",
    "    rtt=rtt\n",
    "    data, time = get_window(f, \"n\")\n",
    "\n",
    "    yf, xf = get_fft(data)\n",
    "    abs_yf = np.abs(yf)\n",
    "#     print(len(abs_yf), len(xf))\n",
    "    sort_abs_yf = sorted(abs_yf)\n",
    "    \n",
    "#     plt.title(\"FFT Decomposition\")\n",
    "#     plt.plot(xf, sort_abs_yf, color='b', alpha=0.5, lw=1)\n",
    "#     plt.scatter(xf, sort_abs_yf, color='r', s=2)\n",
    "#     plt.show()\n",
    "\n",
    "    thresh  = (1/rtt)\n",
    "#     print(\"RTT\", rtt, \"Freq \", thresh)\n",
    "    thresh_ind = 0\n",
    "    for i in range(len(xf)) :\n",
    "        freq = xf[i]\n",
    "        if(freq > thresh):\n",
    "            thresh_ind = i\n",
    "            break\n",
    "#     print(\"Index \", thresh_ind)\n",
    "#     print(xf[0:thresh_ind])\n",
    "#     plt.title(\"Cleaned Frequencies\")\n",
    "#     plt.plot(xf[0:thresh_ind],np.abs(yf[0:thresh_ind]))\n",
    "#     plt.show()\n",
    "\n",
    "    yf_clean = yf\n",
    "    yf_clean[thresh_ind+1:] = 0\n",
    "    new_f_clean = irfft(yf_clean)\n",
    "#     plt.title(\"Frequencies smaller than \" + str(thresh))\n",
    "#     plt.plot(time, data, color=\"b\", alpha=0.5, label='original signal')\n",
    "    start_len = len(time) - len(new_f_clean)\n",
    "\n",
    "    plot_data = new_f_clean\n",
    "    \n",
    "    if norm == 1:\n",
    "        max_data = max(new_f_clean)\n",
    "        min_data = min(new_f_clean)\n",
    "        plot_data = (new_f_clean - min_data)/(max_data - min_data)\n",
    "    if p:\n",
    "        ax.plot(time[start_len:], plot_data, 'k', label='FFT smoothening', linewidth=1.5)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    plot_time = time[start_len:] \n",
    "    return plot_time, plot_data\n",
    "\n",
    "def get_grad(time, data):\n",
    "    new_data = []\n",
    "#     new_data.append(0)\n",
    "    for i in range(1, len(data)):\n",
    "        # experiment change start \n",
    "        diff = time[i]-time[i-1]\n",
    "        \n",
    "        diff = max(0.000001,diff)\n",
    "        # experiment end\n",
    "#         diff=1\n",
    "        new_data.append((data[i]-data[i-1])/(diff))\n",
    "    new_time = time[1:]\n",
    "    plot_data = np.array(new_data)\n",
    "    max_data = max(new_data)\n",
    "    min_data = min(new_data)\n",
    "    new_data = np.array(new_data)\n",
    "    plot_data = (new_data - min_data)/(max_data-min_data)\n",
    "    return new_time, plot_data\n",
    "def plot_d(ax, time, data, c, l):\n",
    "    ax.plot(time, data, color=c, lw=2, label = l)\n",
    "\n",
    "def smooth_grad(grad_time, grad_data):\n",
    "    dt = pd.DataFrame(grad_data)\n",
    "    tm = pd.DataFrame(grad_time)\n",
    "    dt = list(dt.rolling(50, center=True).mean().dropna()[0])\n",
    "    tm = list(tm.rolling(50, center=True).mean().dropna()[0])\n",
    "    return tm, dt\n",
    "\n",
    "def plot_one_bt(files, p):\n",
    "    for f in files:\n",
    "        fs = f.split(\"-\")\n",
    "        # experiment change start \n",
    "        pre = int(fs[2])\n",
    "        post = int(fs[3])\n",
    "        # experiment change end\n",
    "        rtt = float(((pre+post)*2))/1000\n",
    "#         print(rtt)\n",
    "        ax = 0\n",
    "        if p == 'y':\n",
    "            fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "        \n",
    "        time, data = get_fft_smoothening(ax,f,0,rtt,0)\n",
    "#         plot_d(ax,time,data,\"b\",\"FFT Smoothened\" )\n",
    "#         print(len(time), len(data))\n",
    "        time, data = smoothen(time, data, rtt)\n",
    "#         print(len(time), len(data))\n",
    "        if p == 'y':\n",
    "#             plot_d(ax, time, data, \"r\", \"Smoothened\")\n",
    "            plot_data = np.array(data)\n",
    "            plot_data -= min(data)\n",
    "            plot_data /= (max(data)-min(data))\n",
    "            plot_d(ax, time, plot_data, \"g\", \"Smoothened\")\n",
    "#         fd_time, fd_data = get_fd(time, data)\n",
    "#         plot_d(ax, time, data, \"g\")\n",
    "        grad_time, grad_data = get_grad(time, data)\n",
    "#         smooth_grad_time, smooth_grad_data = smooth_grad(grad_time, grad_data)\n",
    "        if p == 'y':\n",
    "#             grad_plot_data += min(data)\n",
    "            plot_d(ax, grad_time, grad_data, \"r\", \"Gradient\")\n",
    "#             plot_d(ax, smooth_grad_time, smooth_grad_data, \"b\", \"Smooth Gradient\")\n",
    "#             start = math.floor(0.05*len(grad_time))\n",
    "            devi = statistics.pstdev(grad_data)\n",
    "            mean = statistics.mean(grad_data)\n",
    "            m = 0.60\n",
    "            plt.fill_between(grad_time, [mean + devi*m for i in range(len(grad_time))], [mean - devi*m for i in range(len(grad_time))], color='y')\n",
    "#         grad_step_time, grad_step_data = get_step_grad(time, data, rtt)\n",
    "#         plot_d(ax, grad_step_time, grad_step_data, \"b\", \"Step Gradient\")\n",
    "#         ax.title.set_text(f)\n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "    return time, data, grad_time, grad_data, rtt\n",
    "#     return time, data \n",
    "def get_time_features_bt(curr_file, p):\n",
    "    main_time, main_data, grad_time, grad_data, rtt= plot_one_bt(curr_file, p)\n",
    "    \n",
    "    data = grad_data\n",
    "    time = grad_time\n",
    "#     start = math.floor(0.05*len(grad_time))\n",
    "    mean = data.mean()\n",
    "#     print(\"Mean\", mean)\n",
    "    sd = statistics.pstdev(data)\n",
    "#     print(\"Std Dev\", sd)\n",
    "    data = abs(data - mean)\n",
    "    features = []\n",
    "    tp = 0\n",
    "    ch_left = 0\n",
    "    ch_right = 0\n",
    "    max_win = 0\n",
    "    min_win = 0\n",
    "    m = 0.60\n",
    "    while time[ch_right] - time[ch_left] < rtt :\n",
    "        max_win = max(max_win, data[ch_right])\n",
    "        ch_right+=1\n",
    "    if max_win > m*sd :\n",
    "        tp = 1\n",
    "\n",
    "    max_win = 0\n",
    "    min_win = 0\n",
    "\n",
    "    ft_left = 0\n",
    "    left = 0\n",
    "    right = 0\n",
    "\n",
    "    while ft_left < len(time) and left < len(time):\n",
    "        while right < len(time) and (time[right] - time[left]) <= rtt:\n",
    "            max_win = max(max_win, data[right])\n",
    "            right+=1\n",
    "        if tp == 0:\n",
    "            if (max_win > m*sd):\n",
    "                features.append([ft_left, left-1, tp])\n",
    "                ft_left = left\n",
    "                tp = 1\n",
    "        if tp == 1:\n",
    "            if (max_win < m*sd):\n",
    "                features.append([ft_left, left-1, tp])\n",
    "                ft_left = left\n",
    "                tp = 0\n",
    "    #     print(left, right, max_win, mean + m*sd)\n",
    "        max_win = 0\n",
    "        left = right \n",
    "\n",
    "    features.append([ft_left, left-1, tp])\n",
    "    return features, main_time, main_data, grad_time, grad_data, rtt\n",
    "def get_amp_grad(features, grad_time, grad_data, rtt):\n",
    "#     mn = grad_data.mean()\n",
    "#     grad_data -= mn\n",
    "#     for ft in features :\n",
    "# #         This idea should be more refined mathematically\n",
    "#         if ft[2]==1:\n",
    "#             grad_data[ft[0]:ft[1]+1]*=2\n",
    "#         if ft[2]==0:\n",
    "#             grad_data[ft[0]:ft[1]+1]/=2\n",
    "#     grad_data += mn\n",
    "#     data = grad_data\n",
    "#     time = grad_time\n",
    "#     mean = data.mean()\n",
    "#     print(\"Mean\", mean)\n",
    "#     sd = statistics.pstdev(data)\n",
    "#     print(\"Std Dev\", sd)\n",
    "#     data = abs(data - mean)\n",
    "#     features = []\n",
    "#     tp = 0\n",
    "#     ch_left = 0\n",
    "#     ch_right = 0\n",
    "#     max_win = 0\n",
    "#     min_win = 0\n",
    "#     m = 2\n",
    "#     while time[ch_right] - time[ch_left] < rtt :\n",
    "#         max_win = max(max_win, data[ch_right])\n",
    "#         ch_right+=1\n",
    "#     if max_win > m*sd :\n",
    "#         tp = 1\n",
    "\n",
    "#     max_win = 0\n",
    "#     min_win = 0\n",
    "\n",
    "#     ft_left = 0\n",
    "#     left = 0\n",
    "#     right = 0\n",
    "\n",
    "#     while ft_left < len(time) and left < len(time):\n",
    "#         while right < len(time) and (time[right] - time[left]) <= rtt:\n",
    "#             max_win = max(max_win, data[right])\n",
    "#             right+=1\n",
    "#         if tp == 0:\n",
    "#             if (max_win > m*sd):\n",
    "#                 features.append([ft_left, left-1, tp])\n",
    "#                 ft_left = left-1\n",
    "#                 tp = 1\n",
    "#         if tp == 1:\n",
    "#             if (max_win < m*sd):\n",
    "#                 features.append([ft_left, left-1, tp])\n",
    "#                 ft_left = left-1\n",
    "#                 tp = 0\n",
    "#     #     print(left, right, max_win, mean + m*sd)\n",
    "#         max_win = 0\n",
    "#         left = right\n",
    "        \n",
    "#     features.append([ft_left, left-1, tp])\n",
    "    pos = 0\n",
    "    for ft in features :\n",
    "        if pos > 0 and pos < len(features)-1 :\n",
    "            if(round(grad_time[ft[1]] - grad_time[ft[0]],3) <= 3*rtt):\n",
    "                if features[pos-1][2] == features[pos+1][2]:\n",
    "                    ft[2] = features[pos-1][2]\n",
    "#                     model = LinearRegression()\n",
    "#                     curr_range = list(range(features[pos-1][0],features[pos-1][1]+1))\n",
    "#                     X = np.reshape(curr_range, (len(curr_range), 1))\n",
    "#                     model.fit(X, data[features[pos-1][0]:features[pos-1][1]+1])\n",
    "#                     left = statistics.mean(model.predict(X))\n",
    "#                     print(\"Left\",left)\n",
    "#                     curr_range = list(range(features[pos+1][0],features[pos+1][1]+1))\n",
    "#                     X = np.reshape(curr_range, (len(curr_range), 1))\n",
    "#                     model.fit(X, data[features[pos+1][0]:features[pos+1][1]+1])\n",
    "#                     right = statistics.mean(model.predict(X))\n",
    "#                     print(\"Right\", right)\n",
    "#                     if left*right < 0 and ft[2] == 0:\n",
    "#                         ft[2] = 1\n",
    "#                     if left*right > 0 and ft[2] == 1:\n",
    "#                         ft[2] = 0            \n",
    "        pos+=1\n",
    "    new_ft = []\n",
    "    start_type = features[0][2]\n",
    "    start = features[0][0]\n",
    "    end = 0\n",
    "    for i in range(len(features)) :\n",
    "        ft = features[i]\n",
    "        curr_type = ft[2]\n",
    "        if curr_type != start_type :\n",
    "            end = ft[0]\n",
    "            new_ft.append([start, end, start_type])\n",
    "            start = end\n",
    "            start_type = ft[2]\n",
    "        if i == len(features)-1:\n",
    "            new_ft.append([start, ft[1], start_type])\n",
    "        \n",
    "    return new_ft, grad_time, grad_data\n",
    "#     return new_ft, grad_time, grad_data\n",
    "def get_features(features, main_time, grad_time):\n",
    "    left = 0\n",
    "    right = 0\n",
    "    result_ft = []\n",
    "    for ft in features:\n",
    "#         print(\"Next Stop\", grad_time[ft[1]])\n",
    "        while(right < len(main_time) and main_time[right] < grad_time[ft[1]]):\n",
    "#             print(main_time[right])\n",
    "            right+=1\n",
    "        result_ft.append((left, right-1, ft[2]))\n",
    "        left = right\n",
    "    if left < right :\n",
    "        result_ft.append((left, right-1, ft[2]))\n",
    "    \n",
    "    return result_ft\n",
    "color = ['r', 'b']\n",
    "def get_new_grad(curr_file, p):\n",
    "    features, main_time, main_data, grad_time, grad_data, rtt = get_time_features_bt(curr_file, p)\n",
    "    features, grad_time, grad_data = get_amp_grad(features, grad_time, grad_data, rtt)\n",
    "    main_features = get_features(features, main_time, grad_time)\n",
    "    if p == 'y' :\n",
    "        fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "#         plot_d(ax, grad_time, grad_data, \"y\", \"Smoothened Gradient\")\n",
    "        for ft in features : \n",
    "    #         print(main_time[ft[1]]-main_time[ft[0]], ft[2])\n",
    "            ax.plot(main_time[ft[0]:ft[1]+1], main_data[ft[0]:ft[1]+1], color = color[ft[2]])\n",
    "        plt.show()\n",
    "    return features, main_time, main_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc9057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_new_grad(['cubic-1-0-50-1000-1-aws'], p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad15568",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, data, grad_time, grad_data, rtt = plot_one_bt(['cubic-1-0-50-1000-2'], p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, data, grad_time, grad_data, rtt = plot_one_bt(['cubic-1-0-50-1000-2'], p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c228222",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, data, grad_time, grad_data, rtt = plot_one_bt(['cubic-1-0-50-1000-2'], p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643fec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, data, grad_time, grad_data, rtt = plot_one_bt(['bbr-1-0-50-1000-2-aws'], p=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import math\n",
    "\n",
    "SHOW=True\n",
    "MULTI_GRAPH=False\n",
    "SMOOTHENING=False\n",
    "ONLY_STATS=False\n",
    "s_factor=0.9\n",
    "\n",
    "'''\n",
    "TODO: \n",
    "o Add functionality where you only plot flows that send more than x bytes of data\n",
    "o Sort stats and graphs by flow size\n",
    "o Organize plots by flow size (larger flows have larger graphs)\n",
    "o Custom smoothening function\n",
    "'''\n",
    "\n",
    "fields=[\"time\", \"frame_time_rel\", \"tcp_time_rel\", \"frame_num\", \"frame_len\", \"ip_src\", \"src_port\", \"ip_dest\", \"dest_port\", \"tcp_len\", \"seq\", \"ack\"]\n",
    "\n",
    "class pkt:\n",
    "    contents=[]\n",
    "    def __init__(self, fields) -> None:\n",
    "        self.contents=[]\n",
    "        for f in fields:\n",
    "            self.contents.append(f)\n",
    "\n",
    "    def get(self, field):\n",
    "        return self.contents[fields.index(field)]\n",
    "        \n",
    "\n",
    "def process_flows(cc, dir):\n",
    "    with open(dir+cc+\"-tcp.csv\") as csv_file:\n",
    "        print(\"Reading \"+dir+cc+\"-tcp.csv...\")\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        total_bytes=0\n",
    "        '''\n",
    "        Flow tracking:\n",
    "        o Identify all packets that are either sourced from or headed to 100.64.0.2\n",
    "        o Group different flows by client's port\n",
    "        '''\n",
    "        flows={}\n",
    "        data_sent=0\n",
    "        port_set = set()\n",
    "        for row in csv_reader:\n",
    "            packet=pkt(row)\n",
    "            validPkt=False\n",
    "            if line_count==0:\n",
    "                # reject the header\n",
    "                line_count+=1\n",
    "                continue\n",
    "            if data_sent == 0 : \n",
    "                if \"100.64.0.\" in packet.get(\"ip_src\"):\n",
    "                    num = int(packet.get(\"ip_src\")[-1])\n",
    "                    if num%2==0:\n",
    "                        data_sent=1\n",
    "                        host_port=packet.get(\"ip_src\")\n",
    "                if \"100.64.0.\" in packet.get(\"ip_dest\"):\n",
    "                    num = int(packet.get(\"ip_dest\")[-1])\n",
    "                    if num%2==0:\n",
    "                        data_sent=1\n",
    "                        host_port=packet.get(\"ip_dest\")\n",
    "                if data_sent == 0:\n",
    "                    continue\n",
    "                    \n",
    "            if packet.get(\"ip_src\")==host_port and packet.get(\"frame_time_rel\")!='' and packet.get(\"ack\")!='': \n",
    "                # we care about this ACK packet\n",
    "                validPkt=True\n",
    "                port=packet.get(\"src_port\")\n",
    "                if port not in flows:\n",
    "                    flows[port]={\"serverip\":packet.get(\"ip_dest\"), \"serverport\":packet.get(\"dest_port\"), \"act_times\":[],\"times\":[], \"windows\":[], \"cwnd\":[], \"bif\":0, \"last_ack\":0, \"last_seq\":0, \"pif\":0}\n",
    "                flows[port][\"act_times\"].append(packet.get(\"time\"))\n",
    "                flows[port][\"times\"].append(float(packet.get(\"frame_time_rel\")))\n",
    "                flows[port][\"bif\"]-=max(0,(int(packet.get(\"ack\"))-int(flows[port][\"last_ack\"])))\n",
    "                flows[port][\"last_ack\"]=max(int(flows[port][\"last_ack\"]),int(packet.get(\"ack\")))\n",
    "                #flows[port][\"windows\"].append(int(flows[port][\"bif\"]))\n",
    "                flows[port][\"pif\"]-=1\n",
    "                flows[port][\"cwnd\"].append(flows[port][\"pif\"])\n",
    "            elif packet.get(\"ip_dest\")==host_port and packet.get(\"frame_time_rel\")!='' and packet.get(\"seq\")!='':\n",
    "                #we care about this Data packet\n",
    "                validPkt=True\n",
    "                port=packet.get(\"dest_port\")\n",
    "                if port not in flows:\n",
    "                    flows[port]={\"serverip\":packet.get(\"ip_src\"), \"serverport\":packet.get(\"src_port\"),\"act_times\":[], \"times\":[], \"windows\":[], \"cwnd\":[], \"bif\":0, \"last_ack\":0, \"last_seq\":0, \"pif\":0}\n",
    "                flows[port][\"times\"].append(float(packet.get(\"frame_time_rel\")))\n",
    "                flows[port][\"act_times\"].append(packet.get(\"time\"))\n",
    "                flows[port][\"bif\"]+=max(0,(int(packet.get(\"seq\"))-int(flows[port][\"last_seq\"])))\n",
    "                flows[port][\"last_seq\"]=max(flows[port][\"last_seq\"],int(packet.get(\"seq\")))\n",
    "                flows[port][\"pif\"]+=1\n",
    "                flows[port][\"cwnd\"].append(flows[port][\"pif\"])\n",
    "            if SMOOTHENING and validPkt and len(flows[port][\"windows\"])>2:\n",
    "                flows[port][\"windows\"].append(int((s_factor*flows[port][\"windows\"][-1])+((1-s_factor)*flows[port][\"bif\"])))\n",
    "            elif validPkt:\n",
    "                flows[port][\"windows\"].append(int(flows[port][\"bif\"]))\n",
    "            line_count+=1\n",
    "            total_bytes+=int(packet.get(\"frame_len\"))\n",
    "            #print(line_count, total_bytes)\n",
    "            \n",
    "#         print(\"total bytes processed:\", total_bytes/1000, \"KBytes for\", cc, \"(unlimited)\")\n",
    "    return flows\n",
    "\n",
    "def custom_smooth_function():\n",
    "    pass\n",
    "\n",
    "def get_flow_stats(flows):\n",
    "    num=len(flows.keys())\n",
    "    print(\"FLOW STATISTICS: \\nNumber of flows: \", num)\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "    print('%6s'%\"port\", '%15s'%\"SrcIP\", '%8s'%\"SrcPort\",  '%8s'%\"duration\",  '%8s'%\"start\",  '%8s'%\"end\", '%8s'%\"Sent (B)\", '%8s'%\"Recv (B)\",)\n",
    "    for k in flows.keys():\n",
    "        print('%6s'%k, '%15s'%flows[k][\"serverip\"], '%8s'%flows[k][\"serverport\"], '%8s'%str('%.2f'%(flows[k][\"times\"][-1]-flows[k][\"times\"][0])), '%8s'%str('%.2f'%flows[k][\"times\"][0]), '%8s'%str('%.2f'%flows[k][\"times\"][-1]), '%8s'%flows[k][\"last_seq\"], '%8s'%flows[k][\"last_ack\"])\n",
    "        #print(\"    * Flow \"+str(k)+\": \", flows[k][\"last_ack\"], \" \", flows[k][\"last_seq\"], \" bytes transfered.\")\n",
    "    return num\n",
    "\n",
    "def run(files):\n",
    "    flows = {}\n",
    "    for f in files:\n",
    "        algo_cc=f\n",
    "        #Get the data for all the flows\n",
    "        print(\"==============================================================================\")\n",
    "        print(\"opening trace ../measurements/\"+algo_cc+\".csv...\")\n",
    "        flows = process_flows(algo_cc, \"./Nebby/measurements/\")\n",
    "        #decide on final graph layout\n",
    "        num = get_flow_stats(flows)\n",
    "\n",
    "        if ONLY_STATS:\n",
    "            sys.exit()\n",
    "\n",
    "        if num==1:\n",
    "            MULTI_GRAPH=False\n",
    "        #grid size\n",
    "        if MULTI_GRAPH:\n",
    "            size=(0,0)\n",
    "            grids={1:(2,2), 2:(2,2), 4:(2,2), 6:(2,3), 9:(3,3), 12:(3,4), 15:(3,5), 16:(4,4), 20:(5,4), 24:(6,4), 30:(6,5), 36:(6,6), 40:(8,5), 42:(8,7), 49:(7,7)}\n",
    "            g=num\n",
    "            while g<=49 and g not in grids:\n",
    "                g+=1\n",
    "            if g in grids.keys():\n",
    "                size=grids[g]\n",
    "            else:\n",
    "                size=grids[49]  \n",
    "            fig, axs = plt.subplots(size[0], size[1])\n",
    "            for i in range(size[0]):\n",
    "                for j in range(size[1]):\n",
    "                    #axs[i][j].legend(loc=\"lower right\")\n",
    "                    if i==size[0]-1:\n",
    "                        axs[i][j].set_xlabel(\"Time (s)\")\n",
    "                    if j==0:\n",
    "                        axs[i][j].set_ylabel(\"Bytes in flight\")\n",
    "        else:\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Bytes in flight\")\n",
    "        counter=0\n",
    "        for port in flows.keys():\n",
    "            if MULTI_GRAPH:  \n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].scatter(flows[port][\"times\"], flows[port][\"windows\"], color=\"#858585\")\n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].plot(flows[port][\"times\"], flows[port][\"windows\"], label=str(port), linestyle=\"solid\")\n",
    "            else:\n",
    "                plt.plot(flows[port][\"times\"], flows[port][\"windows\"], label=str(port), linestyle=\"solid\")\n",
    "                plt.scatter(flows[port][\"times\"], flows[port][\"windows\"], color=\"#858585\")\n",
    "            counter+=1\n",
    "        if MULTI_GRAPH:\n",
    "            counter=0\n",
    "            for port in flows.keys():\n",
    "                axs[counter%size[0]][(counter//size[0])%size[1]].legend()\n",
    "                counter+=1\n",
    "        else:\n",
    "            plt.legend()\n",
    "        if MULTI_GRAPH:\n",
    "            fig.set_size_inches(16, 12)\n",
    "        if SHOW:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(\"../logs/results/\"+algo_cc+\".png\", dpi=600, bbox_inches='tight', pad_inches=0)\n",
    "    return flows\n",
    "\n",
    "def get_window(f,p):\n",
    "    algo_cc = f\n",
    "    flows = process_flows(algo_cc, \"./Nebby/measurements/\")\n",
    "    data = []\n",
    "    time = []\n",
    "    print(flows.keys())\n",
    "    for port in flows.keys():\n",
    "        if flows[port][\"last_ack\"] == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            print(port)\n",
    "            data = flows[port]['windows']\n",
    "            time = flows[port]['times']\n",
    "            print(data)\n",
    "            print(time)\n",
    "            if p == \"p\":\n",
    "                for i in range(len(flows[port]['windows'])):\n",
    "                    print(\"{0:10}{1:10}\".format(flows[port]['times'][i], flows[port]['windows'][i]))\n",
    "        time_index = len(time)-1\n",
    "        for index in range(len(flows[port]['times'])-1):\n",
    "            if flows[port]['times'][index+1] - flows[port]['times'][index] > 1 :\n",
    "                time_index = index\n",
    "        time_last = flows[port]['times'][time_index]\n",
    "        data = data[:time_index+1]\n",
    "        time = time[:time_index+1]\n",
    "    return data, time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
